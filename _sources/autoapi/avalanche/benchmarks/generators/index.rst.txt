:mod:`avalanche.benchmarks.generators`
======================================

.. py:module:: avalanche.benchmarks.generators


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   benchmark_generators/index.rst
   scenario_generators/index.rst


Package Contents
----------------


Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.generators.nc_scenario
   avalanche.benchmarks.generators.ni_scenario
   avalanche.benchmarks.generators.dataset_scenario
   avalanche.benchmarks.generators.filelist_scenario
   avalanche.benchmarks.generators.paths_scenario
   avalanche.benchmarks.generators.tensors_scenario
   avalanche.benchmarks.generators.tensor_scenario
   avalanche.benchmarks.generators.nc_benchmark
   avalanche.benchmarks.generators.ni_benchmark


.. function:: nc_scenario(train_dataset: Union[Sequence[SupportedDataset], SupportedDataset], test_dataset: Union[Sequence[SupportedDataset], SupportedDataset], n_experiences: int, task_labels: bool, *, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Sequence[int] = None, per_exp_classes: Dict[int, int] = None, class_ids_from_zero_from_first_exp: bool = False, class_ids_from_zero_in_each_exp: bool = False, one_dataset_per_exp: bool = False, reproducibility_data: Dict[str, Any] = None) -> NCScenario

   This helper function is DEPRECATED in favor of `nc_benchmark`.

   This method is the high-level specific scenario generator for the
   "New Classes" (NC) case. Given a sequence of train and test datasets creates
   the continual stream of data as a series of experiences. Each experience
   will contain all the patterns belonging to a certain set of classes and a
   class won't be assigned to more than one experience.

   The ``task_labels`` parameter determines if each incremental experience has
   an increasing task label or if, at the contrary, a default task label "0"
   has to be assigned to all experiences. This can be useful when
   differentiating between Single-Incremental-Task and Multi-Task scenarios.

   There are other important parameters that can be specified in order to tweak
   the behaviour of the resulting scenario. Please take a few minutes to read
   and understand them as they may save you a lot of work.

   This generator features a integrated reproducibility mechanism that allows
   the user to store and later re-load a scenario. For more info see the
   ``reproducibility_data`` parameter.

   :param train_dataset: A list of training datasets, or a single dataset.
   :param test_dataset: A list of test datasets, or a single test dataset.
   :param n_experiences: The number of incremental experience. This is not used
       when using multiple train/test datasets with the ``one_dataset_per_exp``
       parameter set to True.
   :param task_labels: If True, each experience will have an ascending task
           label. If False, the task label will be 0 for all the experiences.
   :param shuffle: If True, the class (or experience) order will be shuffled.
       Defaults to True.
   :param seed: If ``shuffle`` is True and seed is not None, the class (or
       experience) order will be shuffled according to the seed. When None, the
       current PyTorch random number generator state will be used. Defaults to
       None.
   :param fixed_class_order: If not None, the class order to use (overrides
       the shuffle argument). Very useful for enhancing reproducibility.
       Defaults to None.
   :param per_exp_classes: Is not None, a dictionary whose keys are
       (0-indexed) experience IDs and their values are the number of classes
       to include in the respective experiences. The dictionary doesn't
       have to contain a key for each experience! All the remaining experiences
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of experiences. For instance,
       if you want to include 50 classes in the first experience
       while equally distributing remaining classes across remaining
       experiences, just pass the "{0: 50}" dictionary as the
       per_experience_classes parameter. Defaults to None.
   :param class_ids_from_zero_from_first_exp: If True, original class IDs
       will be remapped so that they will appear as having an ascending
       order. For instance, if the resulting class order after shuffling
       (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and
       class_ids_from_zero_from_first_exp is True, then all the patterns
       belonging to class 23 will appear as belonging to class "0",
       class "34" will be mapped to "1", class "11" to "2" and so on.
       This is very useful when drawing confusion matrices and when dealing
       with algorithms with dynamic head expansion. Defaults to False.
       Mutually exclusive with the ``class_ids_from_zero_in_each_exp``
       parameter.
   :param class_ids_from_zero_in_each_exp: If True, original class IDs
       will be mapped to range [0, n_classes_in_exp) for each experience.
       Defaults to False. Mutually exclusive with the
       ``class_ids_from_zero_from_first_exp`` parameter.
   :param one_dataset_per_exp: available only when multiple train-test
       datasets are provided. If True, each dataset will be treated as a
       experience. Mutually exclusive with the ``per_experience_classes`` and
       ``fixed_class_order`` parameters. Overrides the ``n_experiences`` 
       parameter. Defaults to False.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :return: A properly initialized :class:`NCScenario` instance.


.. function:: ni_scenario(train_dataset: Union[Sequence[SupportedDataset], SupportedDataset], test_dataset: Union[Sequence[SupportedDataset], SupportedDataset], n_experiences: int, *, task_labels: bool = False, shuffle: bool = True, seed: Optional[int] = None, balance_experiences: bool = False, min_class_patterns_in_exp: int = 0, fixed_exp_assignment: Optional[Sequence[Sequence[int]]] = None, reproducibility_data: Optional[Dict[str, Any]] = None) -> NIScenario

   This helper function is DEPRECATED in favor of `ni_benchmark`.

   This method is the high-level specific scenario generator for the
   "New Instances" (NI) case. Given a sequence of train and test datasets
   creates the continual stream of data as a series of experiences. Each
   experience will contain patterns belonging to the same classes.

   The ``task_labels`` parameter determines if each incremental experience has
   an increasing task label or if, at the contrary, a default task label "0"
   has to be assigned to all experiences. This can be useful when
   differentiating between Single-Incremental-Task and Multi-Task scenarios.

   There are other important parameters that can be specified in order to tweak
   the behaviour of the resulting scenario. Please take a few minutes to read
   and understand them as they may save you a lot of work.

   This generator features an integrated reproducibility mechanism that allows
   the user to store and later re-load a scenario. For more info see the
   ``reproducibility_data`` parameter.

   :param train_dataset: A list of training datasets, or a single dataset.
   :param test_dataset: A list of test datasets, or a single test dataset.
   :param n_experiences: The number of experiences.
   :param task_labels: If True, each experience will have an ascending task
           label. If False, the task label will be 0 for all the experiences.
   :param shuffle: If True, patterns order will be shuffled.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param balance_experiences: If True, pattern of each class will be equally
       spread across all experiences. If False, patterns will be assigned to
       experiences in a complete random way. Defaults to False.
   :param min_class_patterns_in_exp: The minimum amount of patterns of
       every class that must be assigned to every experience. Compatible with
       the ``balance_experiences`` parameter. An exception will be raised if
       this constraint can't be satisfied. Defaults to 0.
   :param fixed_exp_assignment: If not None, the pattern assignment
       to use. It must be a list with an entry for each experience. Each entry
       is a list that contains the indexes of patterns belonging to that
       experience. Overrides the ``shuffle``, ``balance_experiences`` and
       ``min_class_patterns_in_exp`` parameters.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options, including ``fixed_exp_assignment``.
       This is usually a dictionary containing data used to
       reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :return: A properly initialized :class:`NIScenario` instance.


.. function:: dataset_scenario(train_dataset_list: Sequence[SupportedDataset], test_dataset_list: Sequence[SupportedDataset], task_labels: Sequence[int], *, complete_test_set_only: bool = False, dataset_type: AvalancheDatasetType = AvalancheDatasetType.UNDEFINED) -> GenericCLScenario

   This helper function is DEPRECATED in favor of `dataset_benchmark`.

   Creates a generic scenario given a list of datasets and the respective task
   labels. Each training dataset will be considered as a separate training
   experience. Contents of the datasets will not be changed, including the
   targets.

   When loading the datasets from a set of fixed file lists, consider using
   the :func:`filelist_scenario` helper method instead. Also, loading from
   a list of paths is supported through the :func:`paths_scenario` helper.

   In its base form, this function accepts a list of test datasets that must
   contain the same amount of datasets of the training list.
   Those pairs are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` parameter should be set to True
   (see the parameter description for more info).

   Beware that pattern transformations must already be included in the
   datasets (when needed).

   :param train_dataset_list: A list of training datasets.
   :param test_dataset_list: A list of test datasets.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_dataset_list`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_dataset_list``
       parameter must be list with a single element (the complete test set).
       Defaults to False, which means that ``train_dataset_list`` and
       ``test_dataset_list`` must contain the same amount of datasets.
   :param dataset_type: The type of the dataset. Defaults to None, which
       means that the type will be obtained from the input datasets. If input
       datasets are not instances of :class:`AvalancheDataset`, the type
       UNDEFINED will be used.

   :returns: A properly initialized :class:`GenericCLScenario` instance.


.. function:: filelist_scenario(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], *, complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) -> GenericCLScenario

   This helper function is DEPRECATED in favor of `filelist_benchmark`.

   Creates a generic scenario given a list of filelists and the respective task
   labels. A separate dataset will be created for each filelist and each of
   those training datasets will be considered a separate training experience.

   In its base form, this function accepts a list of filelists for the test
   datsets that must contain the same amount of elements of the training list.
   Those pairs of datasets are then used to create the "past", "cumulative"
   (a.k.a. growing) and "future" test sets. However, in certain Continual
   Learning scenarios only the concept of "complete" test set makes sense. In
   that case, the ``complete_test_set_only`` should be set to True (see the
   parameter description for more info).

   This helper functions is the best shot when loading Caffe-style dataset
   based on filelists.

   The resulting benchmark instance and the intermediate datasets used to
   populate it will be of type CLASSIFICATION.

   :param root: The root path of the dataset.
   :param train_file_lists: A list of filelists describing the
       paths of the training patterns for each experience.
   :param test_file_lists: A list of filelists describing the
       paths of the test patterns for each experience.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_file_lists`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_file_lists``
       parameter must be list with a single element (the complete test set).
       Alternatively, can be a plain string or :class:`Path` object.
       Defaults to False, which means that ``train_file_lists`` and
       ``test_file_lists`` must contain the same amount of filelists paths.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param eval_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param eval_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :returns: A properly initialized :class:`GenericCLScenario` instance.


.. function:: paths_scenario(train_list_of_files: Sequence[Sequence[FileAndLabel]], test_list_of_files: Union[Sequence[FileAndLabel], Sequence[Sequence[FileAndLabel]]], task_labels: Sequence[int], *, complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None, dataset_type: AvalancheDatasetType = AvalancheDatasetType.UNDEFINED) -> GenericCLScenario

   This helper function is DEPRECATED in favor of `paths_benchmark`.

   Creates a generic scenario given a list of files and class labels.
   A separate dataset will be created for each list and each of
   those training datasets will be considered a separate training experience.

   This is very similar to `filelist_scenario`, with the main difference being
   that `filelist_scenario` accepts, for each experience, a file list formatted
   in Caffe-style. On the contrary, this accepts a list of tuples where each
   tuple contains two elements: the full path to the pattern and its label.
   Optionally, the tuple may contain a third element describing the bounding
   box of the element to crop. This last bounding box may be useful when trying
   to extract the part of the image depicting the desired element.

   In its base form, this function accepts a list of lists of tuples for the
   test datsets that must contain the same amount of lists of the training
   list. Those pairs of datasets are then used to create the "past",
   "cumulative" (a.k.a. growing) and "future" test sets. However, in certain
   Continual Learning scenarios only the concept of "complete" test set makes
   sense. In that case, the ``complete_test_set_only`` should be set to True
   (see the parameter description for more info).

   The label of each pattern doesn't have to be an int.

   :param train_list_of_files: A list of lists. Each list describes the paths
       and labels of patterns to include in that training experience as tuples.
       Each tuple must contain two elements: the full path to the pattern
       and its class label. Optionally, the tuple may contain a third element
       describing the bounding box to use for cropping (top, left, height,
       width).
   :param test_list_of_files: A list of lists. Each list describes the paths
       and labels of patterns to include in that test experience as tuples.
       Each tuple must contain two elements: the full path to the pattern
       and its class label. Optionally, the tuple may contain a third element
       describing the bounding box to use for cropping (top, left, height,
       width).
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_file_lists`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_file_lists``
       parameter must be list with a single element (the complete test set).
       Alternatively, can be a plain string or :class:`Path` object.
       Defaults to False, which means that ``train_file_lists`` and
       ``test_file_lists`` must contain the same amount of filelists paths.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param eval_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param eval_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.
   :param dataset_type: The type of the dataset. Defaults to UNDEFINED.

   :returns: A properly initialized :class:`GenericCLScenario` instance.


.. function:: tensors_scenario(train_tensors: Sequence[Sequence[Any]], test_tensors: Sequence[Sequence[Any]], task_labels: Sequence[int], *, complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None, dataset_type: AvalancheDatasetType = AvalancheDatasetType.UNDEFINED) -> GenericCLScenario

   This helper function is DEPRECATED in favor of `tensors_benchmark`.

   Creates a generic scenario given lists of Tensors and the respective task
   labels. A separate dataset will be created from each Tensor tuple
   (x, y, ...) and each of those training datasets will be considered a
   separate training experience. Using this helper function is the lowest-level
   way to create a Continual Learning scenario. When possible, consider using
   higher level helpers.

   Experiences are defined by passing lists of tensors as the `train_tensors`
   and `test_tensors` parameter. Those parameters must be lists containing
   sub-lists of tensors, one for each experience. Each tensor defines the value
   of a feature ("x", "y", "z", ...) for all patterns of that experience.

   By default the second tensor of each experience will be used to fill the
   `targets` value (label of each pattern).

   In its base form, the test lists must contain the same amount of elements of
   the training lists. Those pairs of datasets are then used to create the
   "past", "cumulative" (a.k.a. growing) and "future" test sets.
   However, in certain Continual Learning scenarios only the concept of
   "complete" test set makes sense. In that case, the
   ``complete_test_set_only`` should be set to True (see the parameter
   description for more info).

   :param train_tensors: A list of lists. The first list must contain the
       tensors for the first training experience (one tensor per feature), the
       second list must contain the tensors for the second training experience,
       and so on.
   :param test_tensors: A list of lists. The first list must contain the
       tensors for the first test experience (one tensor per feature), the
       second list must contain the tensors for the second test experience,
       and so on.
   :param task_labels: A list of task labels. Must contain a task label for
       each experience. For Single-Incremental-Task (a.k.a. Task-Free)
       scenarios, this is usually a list of zeros. For Multi Task scenario,
       this is usually a list of ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that ``test_tensors`` must
       define a single experience. Defaults to False, which means that
       ``train_tensors`` and ``test_tensors`` must define the same
       amount of experiences.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param eval_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param eval_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.
   :param dataset_type: The type of the dataset. Defaults to UNDEFINED.

   :returns: A properly initialized :class:`GenericCLScenario` instance.


.. function:: tensor_scenario(train_data_x: Sequence[Any], train_data_y: Sequence[Sequence[SupportsInt]], test_data_x: Union[Any, Sequence[Any]], test_data_y: Union[Any, Sequence[Sequence[SupportsInt]]], task_labels: Sequence[int], *, complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None, dataset_type: AvalancheDatasetType = AvalancheDatasetType.UNDEFINED) -> GenericCLScenario

   This helper function is DEPRECATED in favor of `tensors_benchmark`.

   Please consider using :func:`tensors_benchmark` instead. When switching to
   the new function, please keep in mind that the format of the parameters is
   completely different!

   Creates a generic scenario given lists of Tensors and the respective task
   labels. A separate dataset will be created from each Tensor pair (x + y)
   and each of those training datasets will be considered a separate
   training experience. Contents of the datasets will not be changed, including
   the targets. Using this helper function is the lower level way to create a
   Continual Learning scenario. When possible, consider using higher level
   helpers.

   By default the second tensor of each experience will be used to fill the
   `targets` value (label of each pattern).

   In its base form, the test lists must contain the same amount of elements of
   the training lists. Those pairs of datasets are then used to create the
   "past", "cumulative" (a.k.a. growing) and "future" test sets.
   However, in certain Continual Learning scenarios only the concept of
   "complete" test set makes sense. In that case, the
   ``complete_test_set_only`` should be set to True (see the parameter
   description for more info).

   :param train_data_x: A list of Tensors (one per experience) containing the
       patterns of the training sets.
   :param train_data_y: A list of Tensors or int lists containing the
       labels of the patterns of the training sets. Must contain the same
       number of elements of ``train_datasets_x``.
   :param test_data_x: A Tensor or a list of Tensors (one per experience)
       containing the patterns of the test sets.
   :param test_data_y: A Tensor or a list of Tensors or int lists containing
       the labels of the patterns of the test sets. Must contain the same
       number of elements of ``test_datasets_x``.
   :param task_labels: A list of task labels. Must contain the same amount of
       elements of the ``train_datasets_x`` parameter. For
       Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
       a list of zeros. For Multi Task scenario, this is usually a list of
       ascending task labels (starting from 0).
   :param complete_test_set_only: If True, only the complete test set will
       be returned by the scenario. This means that the ``test_datasets_x`` and
       ``test_datasets_y`` parameters must be lists with a single element
       (the complete test set). Defaults to False, which means that
       ``train_file_lists`` and ``test_file_lists`` must contain the same
       amount of filelists paths.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param eval_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param eval_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.
   :param dataset_type: The type of the dataset. Defaults to UNDEFINED.

   :returns: A properly initialized :class:`GenericCLScenario` instance.


.. function:: nc_benchmark(train_dataset: Union[Sequence[SupportedDataset], SupportedDataset], test_dataset: Union[Sequence[SupportedDataset], SupportedDataset], n_experiences: int, task_labels: bool, *, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Sequence[int] = None, per_exp_classes: Dict[int, int] = None, class_ids_from_zero_from_first_exp: bool = False, class_ids_from_zero_in_each_exp: bool = False, one_dataset_per_exp: bool = False, train_transform=None, eval_transform=None, reproducibility_data: Dict[str, Any] = None) -> NCScenario

   This is the high-level benchmark instances generator for the
   "New Classes" (NC) case. Given a sequence of train and test datasets creates
   the continual stream of data as a series of experiences. Each experience
   will contain all the instances belonging to a certain set of classes and a
   class won't be assigned to more than one experience.

   This is the reference helper function for creating instances of Class- or
   Task-Incremental benchmarks.

   The ``task_labels`` parameter determines if each incremental experience has
   an increasing task label or if, at the contrary, a default task label "0"
   has to be assigned to all experiences. This can be useful when
   differentiating between Single-Incremental-Task and Multi-Task scenarios.

   There are other important parameters that can be specified in order to tweak
   the behaviour of the resulting scenario. Please take a few minutes to read
   and understand them as they may save you a lot of work.

   This generator features a integrated reproducibility mechanism that allows
   the user to store and later re-load a scenario. For more info see the
   ``reproducibility_data`` parameter.

   :param train_dataset: A list of training datasets, or a single dataset.
   :param test_dataset: A list of test datasets, or a single test dataset.
   :param n_experiences: The number of incremental experience. This is not used
       when using multiple train/test datasets with the ``one_dataset_per_exp``
       parameter set to True.
   :param task_labels: If True, each experience will have an ascending task
           label. If False, the task label will be 0 for all the experiences.
   :param shuffle: If True, the class (or experience) order will be shuffled.
       Defaults to True.
   :param seed: If ``shuffle`` is True and seed is not None, the class (or
       experience) order will be shuffled according to the seed. When None, the
       current PyTorch random number generator state will be used. Defaults to
       None.
   :param fixed_class_order: If not None, the class order to use (overrides
       the shuffle argument). Very useful for enhancing reproducibility.
       Defaults to None.
   :param per_exp_classes: Is not None, a dictionary whose keys are
       (0-indexed) experience IDs and their values are the number of classes
       to include in the respective experiences. The dictionary doesn't
       have to contain a key for each experience! All the remaining experiences
       will contain an equal amount of the remaining classes. The
       remaining number of classes must be divisible without remainder
       by the remaining number of experiences. For instance,
       if you want to include 50 classes in the first experience
       while equally distributing remaining classes across remaining
       experiences, just pass the "{0: 50}" dictionary as the
       per_experience_classes parameter. Defaults to None.
   :param class_ids_from_zero_from_first_exp: If True, original class IDs
       will be remapped so that they will appear as having an ascending
       order. For instance, if the resulting class order after shuffling
       (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and
       class_ids_from_zero_from_first_exp is True, then all the patterns
       belonging to class 23 will appear as belonging to class "0",
       class "34" will be mapped to "1", class "11" to "2" and so on.
       This is very useful when drawing confusion matrices and when dealing
       with algorithms with dynamic head expansion. Defaults to False.
       Mutually exclusive with the ``class_ids_from_zero_in_each_exp``
       parameter.
   :param class_ids_from_zero_in_each_exp: If True, original class IDs
       will be mapped to range [0, n_classes_in_exp) for each experience.
       Defaults to False. Mutually exclusive with the
       ``class_ids_from_zero_from_first_exp`` parameter.
   :param one_dataset_per_exp: available only when multiple train-test
       datasets are provided. If True, each dataset will be treated as a
       experience. Mutually exclusive with the ``per_experience_classes`` and
       ``fixed_class_order`` parameters. Overrides the ``n_experiences`` 
       parameter. Defaults to False.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param eval_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options. This is usually a dictionary containing
       data used to reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :return: A properly initialized :class:`NCScenario` instance.


.. function:: ni_benchmark(train_dataset: Union[Sequence[SupportedDataset], SupportedDataset], test_dataset: Union[Sequence[SupportedDataset], SupportedDataset], n_experiences: int, *, task_labels: bool = False, shuffle: bool = True, seed: Optional[int] = None, balance_experiences: bool = False, min_class_patterns_in_exp: int = 0, fixed_exp_assignment: Optional[Sequence[Sequence[int]]] = None, train_transform=None, eval_transform=None, reproducibility_data: Optional[Dict[str, Any]] = None) -> NIScenario

   This is the high-level benchmark instances generator for the
   "New Instances" (NI) case. Given a sequence of train and test datasets
   creates the continual stream of data as a series of experiences.

   This is the reference helper function for creating instances of
   Domain-Incremental benchmarks.

   The ``task_labels`` parameter determines if each incremental experience has
   an increasing task label or if, at the contrary, a default task label "0"
   has to be assigned to all experiences. This can be useful when
   differentiating between Single-Incremental-Task and Multi-Task scenarios.

   There are other important parameters that can be specified in order to tweak
   the behaviour of the resulting scenario. Please take a few minutes to read
   and understand them as they may save you a lot of work.

   This generator features an integrated reproducibility mechanism that allows
   the user to store and later re-load a scenario. For more info see the
   ``reproducibility_data`` parameter.

   :param train_dataset: A list of training datasets, or a single dataset.
   :param test_dataset: A list of test datasets, or a single test dataset.
   :param n_experiences: The number of experiences.
   :param task_labels: If True, each experience will have an ascending task
           label. If False, the task label will be 0 for all the experiences.
   :param shuffle: If True, patterns order will be shuffled.
   :param seed: A valid int used to initialize the random number generator.
       Can be None.
   :param balance_experiences: If True, pattern of each class will be equally
       spread across all experiences. If False, patterns will be assigned to
       experiences in a complete random way. Defaults to False.
   :param min_class_patterns_in_exp: The minimum amount of patterns of
       every class that must be assigned to every experience. Compatible with
       the ``balance_experiences`` parameter. An exception will be raised if
       this constraint can't be satisfied. Defaults to 0.
   :param fixed_exp_assignment: If not None, the pattern assignment
       to use. It must be a list with an entry for each experience. Each entry
       is a list that contains the indexes of patterns belonging to that
       experience. Overrides the ``shuffle``, ``balance_experiences`` and
       ``min_class_patterns_in_exp`` parameters.
   :param train_transform: The transformation to apply to the training data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param eval_transform: The transformation to apply to the test data,
       e.g. a random crop, a normalization or a concatenation of different
       transformations (see torchvision.transform documentation for a
       comprehensive list of possible transformations). Defaults to None.
   :param reproducibility_data: If not None, overrides all the other
       scenario definition options, including ``fixed_exp_assignment``.
       This is usually a dictionary containing data used to
       reproduce a specific experiment. One can use the
       ``get_reproducibility_data`` method to get (and even distribute)
       the experiment setup so that it can be loaded by passing it as this
       parameter. In this way one can be sure that the same specific
       experimental setup is being used (for reproducibility purposes).
       Beware that, in order to reproduce an experiment, the same train and
       test datasets must be used. Defaults to None.

   :return: A properly initialized :class:`NIScenario` instance.


.. data:: dataset_benchmark
   

   

.. data:: filelist_benchmark
   

   

.. data:: paths_benchmark
   

   

.. data:: tensors_benchmark
   

   

