:mod:`avalanche.benchmarks.datasets`
====================================

.. py:module:: avalanche.benchmarks.datasets


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   core50/index.rst
   cub200/index.rst
   mini_imagenet/index.rst
   openloris/index.rst
   stream51/index.rst
   tiny_imagenet/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   imagenet_data/index.rst
   omniglot/index.rst
   torchvision_wrapper/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.datasets.CORe50
   avalanche.benchmarks.datasets.CUB200
   avalanche.benchmarks.datasets.MiniImageNetDataset
   avalanche.benchmarks.datasets.OpenLORIS
   avalanche.benchmarks.datasets.TinyImagenet
   avalanche.benchmarks.datasets.Omniglot
   avalanche.benchmarks.datasets.Stream51



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.datasets.MNIST
   avalanche.benchmarks.datasets.FashionMNIST
   avalanche.benchmarks.datasets.KMNIST
   avalanche.benchmarks.datasets.EMNIST
   avalanche.benchmarks.datasets.QMNIST
   avalanche.benchmarks.datasets.FakeData
   avalanche.benchmarks.datasets.CocoCaptions
   avalanche.benchmarks.datasets.CocoDetection
   avalanche.benchmarks.datasets.LSUN
   avalanche.benchmarks.datasets.LSUN
   avalanche.benchmarks.datasets.ImageFolder
   avalanche.benchmarks.datasets.DatasetFolder
   avalanche.benchmarks.datasets.ImageNet
   avalanche.benchmarks.datasets.CIFAR10
   avalanche.benchmarks.datasets.CIFAR100
   avalanche.benchmarks.datasets.STL10
   avalanche.benchmarks.datasets.SVHN
   avalanche.benchmarks.datasets.PhotoTour
   avalanche.benchmarks.datasets.SBU
   avalanche.benchmarks.datasets.Flickr8k
   avalanche.benchmarks.datasets.Flickr30k
   avalanche.benchmarks.datasets.VOCDetection
   avalanche.benchmarks.datasets.VOCSegmentation
   avalanche.benchmarks.datasets.Cityscapes
   avalanche.benchmarks.datasets.SBDataset
   avalanche.benchmarks.datasets.USPS
   avalanche.benchmarks.datasets.Kinetics400
   avalanche.benchmarks.datasets.HMDB51
   avalanche.benchmarks.datasets.UCF101
   avalanche.benchmarks.datasets.CelebA


.. py:class:: CORe50(root=expanduser('~') + '/.avalanche/data/core50/', train=True, transform=ToTensor(), target_transform=None, loader=pil_loader, download=True)

   Bases: :class:`torch.utils.data.dataset.Dataset`

   CORe50 Pytorch Dataset 

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __getitem__(self, index)

      Args:
          index (int): Index

      Returns:
          tuple: (sample, target) where target is class_index of the target
              class.


   .. method:: __len__(self)



.. py:class:: CUB200(root=expanduser('~') + '/.avalanche/data/CUB_200_2011/', train=True, transform=None, target_transform=None, loader=default_loader, download=False)

   Bases: :class:`avalanche.benchmarks.utils.PathsDataset`

   This class extends the basic Pytorch Dataset class to handle list of paths
   as the main data source.

   Creates a File Dataset from a list of files and labels.

   :param root: root path where the data to load are stored. May be None.
   :param files: list of tuples. Each tuple must contain two elements: the
       full path to the pattern and its class label. Optionally, the tuple
       may contain a third element describing the bounding box to use for
       cropping (top, left, height, width).
   :param transform: eventual transformation to add to the input data (x)
   :param target_transform: eventual transformation to add to the targets
       (y)
   :param loader: loader function to use (for the real data) given path.

   .. attribute:: images_folder
      :annotation: = CUB_200_2011/images

      

   .. attribute:: url
      :annotation: = http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz

      

   .. attribute:: filename
      :annotation: = CUB_200_2011.tgz

      

   .. attribute:: tgz_md5
      :annotation: = 97eceeb196236b17998738112f37df78

      

   .. method:: _load_metadata(self)


   .. method:: _check_integrity(self)


   .. method:: _download(self)



.. py:class:: MiniImageNetDataset(imagenet_path: Union[str, Path], split: Literal['all', 'train', 'val', 'test'] = 'all', resize_to: Union[int, Tuple[int, int]] = 84)

   Bases: :class:`torch.utils.data.dataset.Dataset`

   The MiniImageNet dataset.

   This implementation is based on the one from
   https://github.com/yaoyao-liu/mini-imagenet-tools. Differently from that,
   this class doesn't rely on a pre-generated mini imagenet folder. Instead,
   this will use the original ImageNet folder by resizing images on-the-fly.

   The list of included files are the ones defined in the CSVs taken from the
   aforementioned repository. Those CSVs are generated by Ravi and Larochelle.
   See the linked repository for more details.

   Exactly as happens with the torchvision :class:`ImageNet` class, textual
   class labels (wnids) such as "n02119789", "n02102040", etc. are mapped to
   numerical labels based on their ascending order.

   All the fields found in the torchvision implementation of the ImageNet
   dataset (`wnids`, `wnid_to_idx`, `classes`, `class_to_idx`) are available.

   Creates an instance of the Mini ImageNet dataset.

   This dataset allows to obtain the whole dataset or even only specific
   splits. Beware that, when using a split different that "all", the
   returned dataset will contain patterns of a subset of the 100 classes.
   This happens because MiniImagenet was created with the idea of training,
   validating and testing on a disjoint set of classes.

   This implementation uses the filelists provided by
   https://github.com/yaoyao-liu/mini-imagenet-tools, which are the ones
   generated by Ravi and Larochelle (see the linked repo for more details).

   :param imagenet_path: The path to the imagenet folder. This has to be
       the path to the full imagenet 2012 folder (plain, not resized).
       Only the "train" folder will be used. Because of this, passing the
       path to the imagenet 2012 "train" folder is also allowed.
   :param split: The split to obtain. Defaults to "all". Valid values are
       "all", "train", "val" and "test".
   :param resize_to: The size of the output images. Can be an `int` value
       or a tuple of two ints. When passing a single `int` value, images
       will be resized by forcing as 1:1 aspect ratio. Defaults to 84,
       which means that images will have size 84x84.

   .. attribute:: imagenet_path
      

      The path to the "train" folder of full imagenet 2012 directory.


   .. attribute:: split
      :annotation: :Literal['all', 'train', 'val', 'test']

      The required split.


   .. attribute:: resize_to
      :annotation: :Tuple[int, int]

      The size of the output images, as a two ints tuple.


   .. attribute:: image_paths
      :annotation: :List[str] = []

      The paths to images.


   .. attribute:: targets
      :annotation: :List[int] = []

      The class labels for the patterns. Aligned with the image_paths field.


   .. attribute:: wnids
      :annotation: :List[str] = []

      The list of wnids (the textual class labels, such as "n02119789").


   .. attribute:: wnid_to_idx
      :annotation: :Dict[str, int]

      A dictionary mapping wnids to numerical labels in range [0, 100).


   .. attribute:: classes
      :annotation: :List[Tuple[str, ...]] = []

      A list mapping numerical labels (the element index) to a tuple of human
      readable categories. For instance:
      ('great grey owl', 'great gray owl', 'Strix nebulosa').


   .. attribute:: class_to_idx
      :annotation: :Dict[str, int]

      A dictionary mapping each string of the tuples found in the classes 
      field to their numerical label. That is, this dictionary contains the 
      inverse mapping of classes field.


   .. method:: get_train_path(root_path: Union[str, Path])
      :staticmethod:


   .. method:: prepare_dataset(self)


   .. method:: __len__(self)


   .. method:: __getitem__(self, item)



.. py:class:: OpenLORIS(root=expanduser('~') + '/.avalanche/data/openloris/', train=True, transform=ToTensor(), target_transform=None, loader=pil_loader, download=False)

   Bases: :class:`torch.utils.data.Dataset`

   OpenLORIS Pytorch Dataset 

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: __getitem__(self, index)

      Args:
          index (int): Index

      Returns:
          tuple: (sample, target) where target is class_index of the target
              class.


   .. method:: __len__(self)



.. py:class:: TinyImagenet(data_folder=expanduser('~') + '/.avalanche/data/tinyimagenet/', train=True, transform=ToTensor(), target_transform=None, download=True)

   Bases: :class:`torch.utils.data.dataset.Dataset`

   Tiny Imagenet Pytorch Dataset

   Args:
       :param string data_folder: folder in which to download dataset
       :param boolean train: True for train set, False for test set
       :param fun transform: Pytorch transformation founction for x
       :param fun target_transform: Pytorch transformation founction for y
       :param bool download: True for downloading the dataset

   .. method:: download_tinyImageNet(self)

      Downloads the TintImagenet Dataset 


   .. method:: labels2dict(self)

      Returns dictionaries to convert class names into progressive ids
      and viceversa.
      :returns: label2id, id2label: two Python dictionaries.


   .. method:: load_data(self, train=True)

      Load all images paths and targets.

      :param bool train: True for loading the training set, False for the
          test set.
      :return: train_set, test_set: (train_X_paths, train_y).


   .. method:: get_train_images_paths(self, class_name)

      Gets the training set image paths

      :param class_name: names of the classes of the images to be
          collected.
      :returns img_paths: list of strings (paths)


   .. method:: get_test_images_paths(self, class_name)

      Gets the test set image paths

      :param class_name: names of the classes of the images to be
          collected.
      :returns img_paths: list of strings (paths)


   .. method:: __len__(self)

      Returns the lenght of the set 


   .. method:: __getitem__(self, index)

      Returns the index-th x, y pattern of the set 



.. py:class:: Omniglot(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)

   Bases: :class:`torchvision.datasets.Omniglot`

   Custom class used to adapt Omniglot (from Torchvision) and make it
   compatible with the Avalanche API.

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: data(self)
      :property:



.. py:class:: Stream51(root, train=True, transform=None, target_transform=None, loader=pil_loader, download=True)

   Bases: :class:`torch.utils.data.dataset.Dataset`

   Stream-51 Pytorch Dataset 

   Initialize self.  See help(type(self)) for accurate signature.

   .. method:: _instance_ordering(self, data_list, seed)


   .. method:: _class_ordering(self, data_list, class_type, seed)


   .. method:: _make_dataset(self, data_list, ordering='class_instance', seed=666)

      data_list
      for train: [class_id, clip_num, video_num, frame_num, bbox, file_loc]
      for test: [class_id, bbox, file_loc]


   .. method:: __getitem__(self, index)

      Args:
          index (int): Index

      Returns:
          tuple: (sample, target) where target is class_index of the target
          class.


   .. method:: __len__(self)


   .. method:: __repr__(self)

      Return repr(self).



.. function:: MNIST(*args, **kwargs)


.. function:: FashionMNIST(*args, **kwargs)


.. function:: KMNIST(*args, **kwargs)


.. function:: EMNIST(*args, **kwargs)


.. function:: QMNIST(*args, **kwargs)


.. function:: FakeData(*args, **kwargs)


.. function:: CocoCaptions(*args, **kwargs)


.. function:: CocoDetection(*args, **kwargs)


.. function:: LSUN(*args, **kwargs)


.. function:: LSUN(*args, **kwargs)


.. function:: ImageFolder(*args, **kwargs)


.. function:: DatasetFolder(*args, **kwargs)


.. function:: ImageNet(*args, **kwargs)


.. function:: CIFAR10(*args, **kwargs)


.. function:: CIFAR100(*args, **kwargs)


.. function:: STL10(*args, **kwargs)


.. function:: SVHN(*args, **kwargs)


.. function:: PhotoTour(*args, **kwargs)


.. function:: SBU(*args, **kwargs)


.. function:: Flickr8k(*args, **kwargs)


.. function:: Flickr30k(*args, **kwargs)


.. function:: VOCDetection(*args, **kwargs)


.. function:: VOCSegmentation(*args, **kwargs)


.. function:: Cityscapes(*args, **kwargs)


.. function:: SBDataset(*args, **kwargs)


.. function:: USPS(*args, **kwargs)


.. function:: Kinetics400(*args, **kwargs)


.. function:: HMDB51(*args, **kwargs)


.. function:: UCF101(*args, **kwargs)


.. function:: CelebA(*args, **kwargs)


