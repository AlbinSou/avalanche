:mod:`avalanche.benchmarks.utils`
=================================

.. py:module:: avalanche.benchmarks.utils


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   avalanche_dataset/index.rst
   data_loader/index.rst
   dataset_definitions/index.rst
   dataset_utils/index.rst
   datasets_from_filelists/index.rst
   torchvision_wrapper/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.utils.AvalancheDatasetType
   avalanche.benchmarks.utils.AvalancheDataset
   avalanche.benchmarks.utils.AvalancheSubset
   avalanche.benchmarks.utils.AvalancheTensorDataset
   avalanche.benchmarks.utils.AvalancheConcatDataset
   avalanche.benchmarks.utils.PathsDataset
   avalanche.benchmarks.utils.FilelistDataset



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.benchmarks.utils.tensor_as_list
   avalanche.benchmarks.utils.grouped_and_ordered_indexes
   avalanche.benchmarks.utils.concat_datasets_sequentially
   avalanche.benchmarks.utils.as_avalanche_dataset
   avalanche.benchmarks.utils.as_classification_dataset
   avalanche.benchmarks.utils.as_regression_dataset
   avalanche.benchmarks.utils.as_segmentation_dataset
   avalanche.benchmarks.utils.as_undefined_dataset
   avalanche.benchmarks.utils.train_eval_avalanche_datasets
   avalanche.benchmarks.utils.default_image_loader
   avalanche.benchmarks.utils.default_flist_reader
   avalanche.benchmarks.utils.datasets_from_filelists
   avalanche.benchmarks.utils.datasets_from_paths
   avalanche.benchmarks.utils.common_paths_root
   avalanche.benchmarks.utils.ImageFolder
   avalanche.benchmarks.utils.DatasetFolder


.. function:: tensor_as_list(sequence) -> List


.. function:: grouped_and_ordered_indexes(targets: Sequence[int], patterns_indexes: Union[None, Sequence[int]], bucket_classes: bool = True, sort_classes: bool = False, sort_indexes: bool = False) -> Union[List[int], None]

   Given the targets list of a dataset and the patterns to include, returns the
   pattern indexes sorted according to the ``bucket_classes``,
   ``sort_classes`` and ``sort_indexes`` parameters.

   :param targets: The list of pattern targets, as a list.
   :param patterns_indexes: A list of pattern indexes to include in the set.
       If None, all patterns will be included.
   :param bucket_classes: If True, pattern indexes will be returned so that
       patterns will be grouped by class. Defaults to True.
   :param sort_classes: If both ``bucket_classes`` and ``sort_classes`` are
       True, class groups will be sorted by class index. Ignored if
       ``bucket_classes`` is False. Defaults to False.
   :param sort_indexes: If True, patterns indexes will be sorted. When
       bucketing by class, patterns will be sorted inside their buckets.
       Defaults to False.

   :returns: The list of pattern indexes sorted according to the
       ``bucket_classes``, ``sort_classes`` and ``sort_indexes`` parameters or
       None if the patterns_indexes is None and the whole dataset can be taken
       using the existing patterns order.


.. data:: SupportedDataset
   

   

.. py:class:: AvalancheDatasetType

   Bases: :class:`enum.Enum`

   Generic enumeration.

   Derive from this class to define new enumerations.

   Create and return a new object.  See help(type) for accurate signature.

   .. attribute:: UNDEFINED
      

      

   .. attribute:: CLASSIFICATION
      

      

   .. attribute:: REGRESSION
      

      

   .. attribute:: SEGMENTATION
      

      


.. py:class:: AvalancheDataset(dataset: SupportedDataset, *, transform: XTransform = None, target_transform: YTransform = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group: str = None, task_labels: Union[int, Sequence[int]] = None, targets: Sequence[TTargetType] = None, dataset_type: AvalancheDatasetType = None, collate_fn: Callable[[List], Any] = None, targets_adapter: Callable[[Any], TTargetType] = None)

   Bases: :class:`IDatasetWithTargets[T_co, TTargetType]`, :class:`Dataset[T_co]`

   The Dataset used as the base implementation for Avalanche.

   Instances of this dataset are usually returned from scenarios, but it can
   also be used in a completely standalone manner. This dataset can be used
   to apply transformations before returning patterns/targets, it supports
   slicing and advanced indexing and it also contains useful fields as
   `targets`, which contains the pattern labels, and `targets_task_labels`,
   which contains the pattern task labels. The `task_set` field can be used to
   obtain a the subset of patterns labeled with a given task label.

   This dataset can also be used to apply several advanced operations involving
   transformations. For instance, it allows the user to add and replace
   transformations, freeze them so that they can't be changed, etc.

   This dataset also allows the user to keep distinct transformations groups.
   Simply put, a transformation group is a pair of transform+target_transform
   (exactly as in torchvision datasets). This dataset natively supports keeping
   two transformation groups: the first, 'train', contains transformations
   applied to training patterns. Those transformations usually involve some
   kind of data augmentation. The second one is 'eval', that will contain
   transformations applied to test patterns. Having both groups can be
   useful when, for instance, in need to test on the training data (as this
   process usually involves removing data augmentation operations). Switching
   between transformations can be easily achieved by using the
   :func:`train` and :func:`eval` methods.

   Moreover, arbitrary transformation groups can be added and used. For more
   info see the constructor and the :func:`with_transforms` method.

   This dataset will try to inherit the task labels from the input
   dataset. If none are available and none are given via the `task_labels`
   parameter, each pattern will be assigned a default task label "0".
   See the constructor for more details.

   Creates a ``AvalancheDataset`` instance.

   :param dataset: The dataset to decorate. Beware that
       AvalancheDataset will not overwrite transformations already
       applied by this dataset.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       eval (test) transformations. This becomes useful when in need to
       test on the training dataset as test transformations usually don't
       contain random augmentations. ``AvalancheDataset`` natively supports
       the 'train' and 'eval' groups by calling the ``train()`` and
       ``eval()`` methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'eval' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the initial transform group
       to be used. Defaults to None, which means that the current group of
       the input dataset will be used (if an AvalancheDataset). If the
       input dataset is not an AvalancheDataset, then 'train' will be
       used.
   :param task_labels: The task label of each instance. Must be a sequence
       of ints, one for each instance in the dataset. Alternatively can be
       a single int value, in which case that value will be used as the
       task label for all the instances. Defaults to None, which means that
       the dataset will try to obtain the task labels from the original
       dataset. If no task labels could be found, a default task label
       "0" will be applied to all instances.
   :param targets: The label of each pattern. Defaults to None, which
       means that the targets will be retrieved from the dataset (if
       possible).
   :param dataset_type: The type of the dataset. Defaults to None,
       which means that the type will be inferred from the input dataset.
       When the `dataset_type` is different than UNDEFINED, a
       proper value for `collate_fn` and `targets_adapter` will be set.
       If the `dataset_type` is different than UNDEFINED, then
       `collate_fn` and `targets_adapter` must not be set.
   :param collate_fn: The function to use when slicing to merge single
       patterns. In the future this function may become the function
       used in the data loading process, too. If None and the
       `dataset_type` is UNDEFINED, the constructor will check if a
       `collate_fn` field exists in the dataset. If no such field exists,
       the default collate function will be used.
   :param targets_adapter: A function used to convert the values of the
       targets field. Defaults to None. Note: the adapter will not change
       the value of the second element returned by `__getitem__`.
       The adapter is used to adapt the values of the targets field only.

   .. attribute:: dataset_type
      

      The type of this dataset (UNDEFINED, CLASSIFICATION, ...).


   .. attribute:: targets
      :annotation: :Sequence[TTargetType]

      A sequence of values describing the label of each pattern contained in
      the dataset.


   .. attribute:: targets_task_labels
      :annotation: :Sequence[int]

      A sequence of ints describing the task label of each pattern contained 
      in the dataset.


   .. attribute:: tasks_pattern_indices
      :annotation: :Dict[int, Sequence[int]]

      A dictionary mapping task labels to the indices of the patterns with 
      that task label. If you need to obtain the subset of patterns labeled
      with a certain task label, consider using the `task_set` field.


   .. attribute:: collate_fn
      

      The collate function to use when creating mini-batches from this
      dataset.


   .. attribute:: task_set
      

      A dictionary that can be used to obtain the subset of patterns given
      a specific task label.


   .. attribute:: current_transform_group
      

      The name of the transform group currently in use.


   .. attribute:: transform_groups
      :annotation: :Dict[str, Tuple[XTransform, YTransform]]

      A dictionary containing the transform groups. Transform groups are
      used to quickly switch between training and test (eval) transformations.
      This becomes useful when in need to test on the training dataset as test
      transformations usually don't contain random augmentations.

      AvalancheDataset natively supports switching between the 'train' and
      'eval' groups by calling the ``train()`` and ``eval()`` methods. When
      using custom groups one can use the ``with_transforms(group_name)``
      method instead.

      May be null, which means that the current transforms will be used to
      handle both 'train' and 'eval' groups.


   .. attribute:: transform
      :annotation: :XTransform

      A function/transform that takes in an PIL image and returns a 
      transformed version.


   .. attribute:: target_transform
      :annotation: :YTransform

      A function/transform that takes in the target and transforms it.


   .. method:: __add__(self, other: Dataset) -> 'AvalancheDataset'


   .. method:: __radd__(self, other: Dataset) -> 'AvalancheDataset'


   .. method:: __getitem__(self, idx) -> Union[T_co, Sequence[T_co]]


   .. method:: __len__(self)


   .. method:: train(self)

      Returns a new dataset with the transformations of the 'train' group
      loaded.

      The current dataset will not be affected.

      :return: A new dataset with the training transformations loaded.


   .. method:: eval(self)

      Returns a new dataset with the transformations of the 'eval' group
      loaded.

      Eval transformations usually don't contain augmentation procedures.
      This function may be useful when in need to test on training data
      (for instance, in order to run a validation pass).

      The current dataset will not be affected.

      :return: A new dataset with the eval transformations loaded.


   .. method:: freeze_transforms(self: TAvalancheDataset) -> TAvalancheDataset

      Returns a new dataset where the current transformations are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. Please note that transformations of all groups
      will be frozen. If you want to freeze a specific group, please use
      ``freeze_group_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the current transformations frozen.


   .. method:: freeze_group_transforms(self: TAvalancheDataset, group_name: str) -> TAvalancheDataset

      Returns a new dataset where the transformations for a specific group
      are frozen.

      Frozen transformations will be permanently glued to the original
      dataset so that they can't be changed anymore. This is usually done
      when using transformations to create derived datasets: in this way
      freezing the transformations will ensure that the user won't be able
      to inadvertently change them by directly setting the transformations
      field or by using the other transformations utility methods like
      ``replace_transforms``. To freeze transformations of all groups
      please use ``freeze_transforms``.

      The current dataset will not be affected.

      :return: A new dataset with the transformations frozen for the given
          group.


   .. method:: get_transforms(self: TAvalancheDataset, transforms_group: str = None) -> Tuple[Any, Any]

      Returns the transformations given a group.

      Beware that this will not return the frozen transformations, nor the
      ones included in the wrapped dataset. Only transformations directly
      attached to this dataset will be returned.

      :param transforms_group: The transformations group. Defaults to None,
          which means that the current group is returned.
      :return: The transformation group, as a tuple
          (transform, target_transform).


   .. method:: add_transforms(self: TAvalancheDataset, transform: Callable[[Any], Any] = None, target_transform: Callable[[int], int] = None) -> TAvalancheDataset

      Returns a new dataset with the given transformations added to
      the existing ones.

      The transformations will be added to the current transformations group.
      Other transformation groups will not be affected.

      The given transformations will be added "at the end" of previous
      transformations of the current transformations group. This means
      that existing transformations will be applied to the patterns first.

      The current dataset will not be affected.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the added transformations.


   .. method:: add_transforms_to_group(self: TAvalancheDataset, group_name: str, transform: Callable[[Any], Any] = None, target_transform: Callable[[int], int] = None) -> TAvalancheDataset

      Returns a new dataset with the given transformations added to
      the existing ones for a certain group.

      The transformations will be added to the given transformations group.
      Other transformation groups will not be affected. The group must
      already exist.

      The given transformations will be added "at the end" of previous
      transformations of that group. This means that existing transformations
      will be applied to the patterns first.

      The current dataset will not be affected.

      :param group_name: The name of the group.
      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the added transformations.


   .. method:: replace_transforms(self: TAvalancheDataset, transform: XTransform, target_transform: YTransform, group: str = None) -> TAvalancheDataset

      Returns a new dataset with the existing transformations replaced with
      the given ones.

      The given transformations will replace the ones of the current
      transformations group. Other transformation groups will not be affected.

      If the original dataset is an instance of :class:`AvalancheDataset`,
      then transformations of the original set will be considered as well
      (the original dataset will be left untouched).

      The current dataset will not be affected.

      Note that this function will not override frozen transformations. This
      will also not affect transformations found in datasets that are not
      instances of :class:`AvalancheDataset`.

      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :param group: The transforms group to replace. Defaults to None, which
          means that the current group will be replaced.
      :return: A new dataset with the new transformations.


   .. method:: with_transforms(self: TAvalancheDataset, group_name: str) -> TAvalancheDataset

      Returns a new dataset with the transformations of a different group
      loaded.

      The current dataset will not be affected.

      :param group_name: The name of the transformations group to use.
      :return: A new dataset with the new transformations.


   .. method:: add_transforms_group(self: TAvalancheDataset, group_name: str, transform: XTransform, target_transform: YTransform) -> TAvalancheDataset

      Returns a new dataset with a new transformations group.

      The current dataset will not be affected.

      This method raises an exception if a group with the same name already
      exists.

      :param group_name: The name of the new transformations group.
      :param transform: A function/transform that takes the X value of a
          pattern from the original dataset and returns a transformed version.
      :param target_transform: A function/transform that takes in the target
          and transforms it.
      :return: A new dataset with the new transformations.



.. py:class:: AvalancheSubset(dataset: SupportedDataset, indices: Sequence[int] = None, *, class_mapping: Sequence[int] = None, transform: Callable[[Any], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group: str = None, task_labels: Union[int, Sequence[int]] = None, targets: Sequence[TTargetType] = None, dataset_type: AvalancheDatasetType = None, collate_fn: Callable[[List], Any] = None, targets_adapter: Callable[[Any], TTargetType] = None)

   Bases: :class:`AvalancheDataset[T_co, TTargetType]`

   A Dataset that behaves like a PyTorch :class:`torch.utils.data.Subset`.
   This Dataset also supports transformations, slicing, advanced indexing,
   the targets field, class mapping and all the other goodies listed in
   :class:`AvalancheDataset`.

   Creates an ``AvalancheSubset`` instance.

   :param dataset: The whole dataset.
   :param indices: Indices in the whole set selected for subset. Can
       be None, which means that the whole dataset will be returned.
   :param class_mapping: A list that, for each possible target (Y) value,
       contains its corresponding remapped value. Can be None.
       Beware that setting this parameter will force the final
       dataset type to be CLASSIFICATION or UNDEFINED.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       eval (test) transformations. This becomes useful when in need to
       test on the training dataset as test transformations usually don't
       contain random augmentations. ``AvalancheDataset`` natively supports
       the 'train' and 'eval' groups by calling the ``train()`` and
       ``eval()`` methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'eval' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the initial transform group
       to be used. Defaults to None, which means that the current group of
       the input dataset will be used (if an AvalancheDataset). If the
       input dataset is not an AvalancheDataset, then 'train' will be
       used.
   :param task_labels: The task label for each instance. Must be a sequence
       of ints, one for each instance in the dataset. This can either be a
       list of task labels for the original dataset or the list of task
       labels for the instances of the subset (an automatic detection will
       be made). Alternatively can be a single int value, in which case
       that value will be used as the task label for all the instances.
       Defaults to None, which means that the dataset will try to
       obtain the task labels from the original dataset. If no task labels
       could be found, a default task label "0" will be applied to all
       instances.
   :param targets: The label of each pattern. Defaults to None, which
       means that the targets will be retrieved from the dataset (if
       possible). This can either be a list of labels for the original
       dataset or the list of labels for the patterns of the subset (an
       automatic detection will be made).
   :param dataset_type: The type of the dataset. Defaults to None,
       which means that the type will be inferred from the input dataset.
       When the `dataset_type` is different than UNDEFINED, a
       proper value for `collate_fn` and `targets_adapter` will be set.
       If the `dataset_type` is different than UNDEFINED, then
       `collate_fn` and `targets_adapter` must not be set.
       The only exception to this rule regards `class_mapping`.
       If `class_mapping` is set, the final dataset_type
       (as set by this parameter or detected from the subset) must be
       CLASSIFICATION or UNDEFINED.
   :param collate_fn: The function to use when slicing to merge single
       patterns. In the future this function may become the function
       used in the data loading process, too. If None and the
       `dataset_type` is UNDEFINED, the constructor will check if a
       `collate_fn` field exists in the dataset. If no such field exists,
       the default collate function will be used.
   :param targets_adapter: A function used to convert the values of the
       targets field. Defaults to None. Note: the adapter will not change
       the value of the second element returned by `__getitem__`.
       The adapter is used to adapt the values of the targets field only.


.. py:class:: AvalancheTensorDataset(*dataset_tensors: Sequence, transform: Callable[[Any], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group: str = 'train', task_labels: Union[int, Sequence[int]] = None, targets: Sequence[TTargetType] = None, dataset_type: AvalancheDatasetType = AvalancheDatasetType.UNDEFINED, collate_fn: Callable[[List], Any] = None, targets_adapter: Callable[[Any], TTargetType] = None)

   Bases: :class:`AvalancheDataset[T_co, TTargetType]`

   A Dataset that wraps existing ndarrays, Tensors, lists... to provide
   basic Dataset functionalities. Very similar to TensorDataset from PyTorch,
   this Dataset also supports transformations, slicing, advanced indexing,
   the targets field and all the other goodies listed in
   :class:`AvalancheDataset`.

   Creates a ``AvalancheTensorDataset`` instance.

   :param dataset_tensors: Sequences, Tensors or ndarrays representing the
       content of the dataset.
   :param transform: A function/transform that takes in a single element
       from the first tensor and returns a transformed version.
   :param target_transform: A function/transform that takes a single
       element of the second tensor and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       eval (test) transformations. This becomes useful when in need to
       test on the training dataset as test transformations usually don't
       contain random augmentations. ``AvalancheDataset`` natively supports
       the 'train' and 'eval' groups by calling the ``train()`` and
       ``eval()`` methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'eval' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the transform group
       to be used. Defaults to 'train'.
   :param task_labels: The task labels for each pattern. Must be a sequence
       of ints, one for each pattern in the dataset. Alternatively can be a
       single int value, in which case that value will be used as the task
       label for all the instances. Defaults to None, which means that a
       default task label "0" will be applied to all patterns.
   :param targets: The label of each pattern. Defaults to None, which
       means that the targets will be retrieved from the dataset.
       Otherwise, can be 1) a sequence of values containing as many
       elements as the number of patterns, or 2) the index of the sequence
       to use as the targets field. When using the default value of None,
       the targets field will be populated using the second
       tensor. If dataset is made of only one tensor, then that tensor will
       be used for the targets field, too.
   :param dataset_type: The type of the dataset. Defaults to UNDEFINED.
       Setting this parameter will automatically set a proper value for
       `collate_fn` and `targets_adapter`. If this parameter is set to a
       value different from UNDEFINED then `collate_fn` and
       `targets_adapter` must not be set.
   :param collate_fn: The function to use when slicing to merge single
       patterns. In the future this function may become the function
       used in the data loading process, too.
   :param targets_adapter: A function used to convert the values of the
       targets field. Defaults to None. Note: the adapter will not change
       the value of the second element returned by `__getitem__`.
       The adapter is used to adapt the values of the targets field only.


.. py:class:: AvalancheConcatDataset(datasets: Sequence[SupportedDataset], *, transform: Callable[[Any], Any] = None, target_transform: Callable[[int], int] = None, transform_groups: Dict[str, Tuple[XTransform, YTransform]] = None, initial_transform_group: str = None, task_labels: Union[int, Sequence[int], Sequence[Sequence[int]]] = None, targets: Union[Sequence[TTargetType], Sequence[Sequence[TTargetType]]] = None, dataset_type: AvalancheDatasetType = None, collate_fn: Callable[[List], Any] = None, targets_adapter: Callable[[Any], TTargetType] = None)

   Bases: :class:`AvalancheDataset[T_co, TTargetType]`

   A Dataset that behaves like a PyTorch
   :class:`torch.utils.data.ConcatDataset`. However, this Dataset also supports
   transformations, slicing, advanced indexing and the targets field and all
   the other goodies listed in :class:`AvalancheDataset`.

   This dataset guarantees that the operations involving the transformations
   and transformations groups are consistent across the concatenated dataset
   (if they are subclasses of :class:`AvalancheDataset`).

   Creates a ``AvalancheConcatDataset`` instance.

   :param datasets: A sequence of datasets.
   :param transform: A function/transform that takes the X value of a
       pattern from the original dataset and returns a transformed version.
   :param target_transform: A function/transform that takes in the target
       and transforms it.
   :param transform_groups: A dictionary containing the transform groups.
       Transform groups are used to quickly switch between training and
       eval (test) transformations. This becomes useful when in need to
       test on the training dataset as test transformations usually don't
       contain random augmentations. ``AvalancheDataset`` natively supports
       the 'train' and 'eval' groups by calling the ``train()`` and
       ``eval()`` methods. When using custom groups one can use the
       ``with_transforms(group_name)`` method instead. Defaults to None,
       which means that the current transforms will be used to
       handle both 'train' and 'eval' groups (just like in standard
       ``torchvision`` datasets).
   :param initial_transform_group: The name of the initial transform group
       to be used. Defaults to None, which means that if all
       AvalancheDatasets in the input datasets list agree on a common
       group (the "current group" is the same for all datasets), then that
       group will be used as the initial one. If the list of input datasets
       does not contain an AvalancheDataset or if the AvalancheDatasets
       do not agree on a common group, then 'train' will be used.
   :param targets: The label of each pattern. Can either be a sequence of
       labels or, alternatively, a sequence containing sequences of labels
       (one for each dataset to be concatenated). Defaults to None, which
       means that the targets will be retrieved from the datasets (if
       possible).
   :param task_labels: The task labels for each pattern. Must be a sequence
       of ints, one for each pattern in the dataset. Alternatively, task
       labels can be expressed as a sequence containing sequences of ints
       (one for each dataset to be concatenated) or even a single int,
       in which case that value will be used as the task label for all
       instances. Defaults to None, which means that the dataset will try
       to obtain the task labels from the original datasets. If no task
       labels could be found for a dataset, a default task label "0" will
       be applied to all patterns of that dataset.
   :param dataset_type: The type of the dataset. Defaults to None,
       which means that the type will be inferred from the list of
       input datasets. When `dataset_type` is None and the list of datasets
       contains incompatible types, an error will be raised.
       A list of datasets is compatible if they all have
       the same type. Datasets that are not instances of `AvalancheDataset`
       and instances of `AvalancheDataset` with type `UNDEFINED`
       are always compatible with other types.
       When the `dataset_type` is different than UNDEFINED, a
       proper value for `collate_fn` and `targets_adapter` will be set.
       If the `dataset_type` is different than UNDEFINED, then
       `collate_fn` and `targets_adapter` must not be set.
   :param collate_fn: The function to use when slicing to merge single
       patterns. In the future this function may become the function
       used in the data loading process, too. If None, the constructor
       will check if a `collate_fn` field exists in the first dataset. If
       no such field exists, the default collate function will be used.
       Beware that the chosen collate function will be applied to all
       the concatenated datasets even if a different collate is defined
       in different datasets.
   :param targets_adapter: A function used to convert the values of the
       targets field. Defaults to None. Note: the adapter will not change
       the value of the second element returned by `__getitem__`.
       The adapter is used to adapt the values of the targets field only.

   .. method:: __len__(self) -> int



.. function:: concat_datasets_sequentially(train_dataset_list: Sequence[ISupportedClassificationDataset], test_dataset_list: Sequence[ISupportedClassificationDataset]) -> Tuple[AvalancheConcatDataset, AvalancheConcatDataset, List[list]]

   Concatenates a list of datasets. This is completely different from
   :class:`ConcatDataset`, in which datasets are merged together without
   other processing. Instead, this function re-maps the datasets class IDs.
   For instance:
   let the dataset[0] contain patterns of 3 different classes,
   let the dataset[1] contain patterns of 2 different classes, then class IDs
   will be mapped as follows:

   dataset[0] class "0" -> new class ID is "0"

   dataset[0] class "1" -> new class ID is "1"

   dataset[0] class "2" -> new class ID is "2"

   dataset[1] class "0" -> new class ID is "3"

   dataset[1] class "1" -> new class ID is "4"

   ... -> ...

   dataset[-1] class "C-1" -> new class ID is "overall_n_classes-1"

   In contrast, using PyTorch ConcatDataset:

   dataset[0] class "0" -> ID is "0"

   dataset[0] class "1" -> ID is "1"

   dataset[0] class "2" -> ID is "2"

   dataset[1] class "0" -> ID is "0"

   dataset[1] class "1" -> ID is "1"

   Note: ``train_dataset_list`` and ``test_dataset_list`` must have the same
   number of datasets.

   :param train_dataset_list: A list of training datasets
   :param test_dataset_list: A list of test datasets

   :returns: A concatenated dataset.


.. function:: as_avalanche_dataset(dataset: ISupportedClassificationDataset[T_co], dataset_type: AvalancheDatasetType = None) -> AvalancheDataset[T_co, TTargetType]


.. function:: as_classification_dataset(dataset: ISupportedClassificationDataset[T_co]) -> AvalancheDataset[T_co, int]


.. function:: as_regression_dataset(dataset: ISupportedClassificationDataset[T_co]) -> AvalancheDataset[T_co, Any]


.. function:: as_segmentation_dataset(dataset: ISupportedClassificationDataset[T_co]) -> AvalancheDataset[T_co, Any]


.. function:: as_undefined_dataset(dataset: ISupportedClassificationDataset[T_co]) -> AvalancheDataset[T_co, Any]


.. function:: train_eval_avalanche_datasets(train_dataset: ISupportedClassificationDataset, test_dataset: ISupportedClassificationDataset, train_transformation, eval_transformation, dataset_type=None)


.. function:: default_image_loader(path)

   Sets the default image loader for the Pytorch Dataset.

   :param path: relative or absolute path of the file to load.

   :returns: Returns the image as a RGB PIL image.


.. function:: default_flist_reader(flist, root)

   This reader reads a filelist and return a list of paths.

   :param flist: path of the flislist to read. The flist format should be:
       impath label, impath label,  ...(same to caffe's filelist)
   :param root: path to the dataset root. Each file defined in the file list
       will be searched in <root>/<impath>.

   :returns: Returns a list of paths (the examples to be loaded).


.. py:class:: PathsDataset(root, files, transform=None, target_transform=None, loader=default_image_loader)

   Bases: :class:`torch.utils.data.Dataset`

   This class extends the basic Pytorch Dataset class to handle list of paths
   as the main data source.

   Creates a File Dataset from a list of files and labels.

   :param root: root path where the data to load are stored. May be None.
   :param files: list of tuples. Each tuple must contain two elements: the
       full path to the pattern and its class label. Optionally, the tuple
       may contain a third element describing the bounding box to use for
       cropping (top, left, height, width).
   :param transform: eventual transformation to add to the input data (x)
   :param target_transform: eventual transformation to add to the targets
       (y)
   :param loader: loader function to use (for the real data) given path.

   .. method:: __getitem__(self, index)

      Returns next element in the dataset given the current index.

      :param index: index of the data to get.
      :return: loaded item.


   .. method:: __len__(self)

      Returns the total number of elements in the dataset.

      :return: Total number of dataset items.



.. py:class:: FilelistDataset(root, flist, transform=None, target_transform=None, flist_reader=default_flist_reader, loader=default_image_loader)

   Bases: :class:`avalanche.benchmarks.utils.datasets_from_filelists.PathsDataset`

   This class extends the basic Pytorch Dataset class to handle filelists as
   main data source.

           This reader reads a filelist and return a list of paths.

           :param root: root path where the data to load are stored. May be None.
           :param flist: path of the flislist to read. The flist format should be:
               impath label
   impath label
    ...(same to caffe's filelist).
           :param transform: eventual transformation to add to the input data (x).
           :param target_transform: eventual transformation to add to the targets
               (y).
           :param flist_reader: loader function to use (for the filelists) given
               path.
           :param loader: loader function to use (for the real data) given path.
           


.. function:: datasets_from_filelists(root, train_filelists, test_filelists, complete_test_set_only=False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None)

   This reader reads a list of Caffe-style filelists and returns the proper
   Dataset objects.

   A Caffe-style list is just a text file where, for each line, two elements
   are described: the path to the pattern (relative to the root parameter)
   and its class label. Those two elements are separated by a single white
   space.

   This method reads each file list and returns a separate
   dataset for each of them.

   Beware that the parameters must be **list of paths to Caffe-style
   filelists**. If you need to create a dataset given a list of
   **pattern paths**, use `datasets_from_paths` instead.

   :param root: root path where the data to load are stored. May be None.
   :param train_filelists: list of paths to train filelists. The flist format
       should be: impath label\nimpath label\n ...(same to Caffe's filelist).
   :param test_filelists: list of paths to test filelists. It can be also a
       single path when the datasets is the same for each batch.
   :param complete_test_set_only: if True, test_filelists must contain
       the path to a single filelist that will serve as the complete test set.
       Alternatively, test_filelists can be the path (str) to the complete test
       set filelist. If False, train_filelists and test_filelists must contain
       the same amount of filelists paths. Defaults to False.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :return: list of tuples (train dataset, test dataset) for each train
       filelist in the list.


.. function:: datasets_from_paths(train_list, test_list, complete_test_set_only=False, train_transform=None, train_target_transform=None, test_transform=None, test_target_transform=None)

   This utility takes, for each dataset to generate, a list of tuples each
   containing two elements: the full path to the pattern and its class label.
   Optionally, the tuple may contain a third element describing the bounding
   box to use for cropping.

   This is equivalent to `datasets_from_filelists`, which description
   contains more details on the behaviour of this utility. The two utilities
   differ in which `datasets_from_filelists` accepts paths to Caffe-style
   filelists while this one is able to create the datasets from an in-memory
   list.

   Note: this utility may try to detect (and strip) the common root path of
   all patterns in order to save some RAM memory.

   :param train_list: list of lists. Each list must contain tuples of two
       elements: the full path to the pattern and its class label. Optionally,
       the tuple may contain a third element describing the bounding box to use
       for cropping (top, left, height, width).
   :param test_list: list of lists. Each list must contain tuples of two
       elements: the full path to the pattern and its class label. Optionally,
       the tuple may contain a third element describing the bounding box to use
       for cropping (top, left, height, width). It can be also a single list
       when the test dataset is the same for each experience.
   :param complete_test_set_only: if True, test_list must contain a single list
       that will serve as the complete test set. If False, train_list and
       test_list must describe the same amount of datasets. Defaults to False.
   :param train_transform: The transformation to apply to training patterns.
       Defaults to None.
   :param train_target_transform: The transformation to apply to training
       patterns targets. Defaults to None.
   :param test_transform: The transformation to apply to test patterns.
       Defaults to None.
   :param test_target_transform: The transformation to apply to test
       patterns targets. Defaults to None.

   :return: A list of tuples (train dataset, test dataset).


.. function:: common_paths_root(exp_list)


.. function:: ImageFolder(*args, **kwargs)


.. function:: DatasetFolder(*args, **kwargs)


