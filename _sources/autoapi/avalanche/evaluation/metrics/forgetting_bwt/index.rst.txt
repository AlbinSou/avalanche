:mod:`avalanche.evaluation.metrics.forgetting_bwt`
==================================================

.. py:module:: avalanche.evaluation.metrics.forgetting_bwt


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.forgetting_bwt.Forgetting
   avalanche.evaluation.metrics.forgetting_bwt.GenericExperienceForgetting
   avalanche.evaluation.metrics.forgetting_bwt.ExperienceForgetting
   avalanche.evaluation.metrics.forgetting_bwt.GenericStreamForgetting
   avalanche.evaluation.metrics.forgetting_bwt.StreamForgetting
   avalanche.evaluation.metrics.forgetting_bwt.GenericTaskForgetting
   avalanche.evaluation.metrics.forgetting_bwt.TaskForgetting
   avalanche.evaluation.metrics.forgetting_bwt.BWT
   avalanche.evaluation.metrics.forgetting_bwt.ExperienceBWT
   avalanche.evaluation.metrics.forgetting_bwt.StreamBWT
   avalanche.evaluation.metrics.forgetting_bwt.TaskBWT



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.forgetting_bwt.forgetting_metrics
   avalanche.evaluation.metrics.forgetting_bwt.bwt_metrics


.. py:class:: Forgetting

   Bases: :class:`Metric[Union[float, None, Dict[int, float]]]`

   The standalone Forgetting metric.
   This metric returns the forgetting relative to a specific key.
   Alternatively, this metric returns a dict in which each key is associated
   to the forgetting.
   Forgetting is computed as the difference between the first value recorded
   for a specific key and the last value recorded for that key.
   The value associated to a key can be update with the `update` method.

   At initialization, this metric returns an empty dictionary.

   Creates an instance of the standalone Forgetting metric

   .. attribute:: initial
      :annotation: :Dict[int, float]

      The initial value for each key.


   .. attribute:: last
      :annotation: :Dict[int, float]

      The last value detected for each key


   .. method:: update_initial(self, k, v)


   .. method:: update_last(self, k, v)


   .. method:: update(self, k, v, initial=False)


   .. method:: result(self, k=None) -> Union[float, None, Dict[int, float]]

      Forgetting is returned only for keys encountered twice.

      :param k: the key for which returning forgetting. If k has not
          updated at least twice it returns None. If k is None,
          forgetting will be returned for all keys encountered at least
          twice.

      :return: the difference between the first and last value encountered
          for k, if k is not None. It returns None if k has not been updated
          at least twice. If k is None, returns a dictionary
          containing keys whose value has been updated at least twice. The
          associated value is the difference between the first and last
          value recorded for that key.


   .. method:: reset_last(self) -> None


   .. method:: reset(self) -> None

      Resets the metric internal state.

      :return: None.



.. py:class:: GenericExperienceForgetting

   Bases: :class:`PluginMetric[Dict[int, float]]`

   The GenericExperienceForgetting metric, describing the change in
   a metric detected for a certain experience. The user should
   subclass this and provide the desired metric.

   In particular, the user should override:
   * __init__ by calling `super` and instantiating the `self.current_metric`
   property as a valid avalanche metric
   * `metric_update`, to update `current_metric`
   * `metric_result` to get the result from `current_metric`.
   * `__str__` to define the experience forgetting  name.

   This plugin metric, computed separately for each experience,
   is the difference between the metric result obtained after
   first training on a experience and the metric result obtained
   on the same experience at the end of successive experiences.

   This metric is computed during the eval phase only.

   Creates an instance of the GenericExperienceForgetting metric.

   .. attribute:: forgetting
      

      The general metric to compute forgetting


   .. attribute:: eval_exp_id
      

      The current evaluation experience id


   .. attribute:: train_exp_id
      

      The last encountered training experience id


   .. method:: reset(self) -> None

      Resets the metric.

      Beware that this will also reset the initial metric of each
      experience!

      :return: None.


   .. method:: reset_last(self) -> None

      Resets the last metric value.

      This will preserve the initial metric value of each experience.
      To be used at the beginning of each eval experience.

      :return: None.


   .. method:: update(self, k, v, initial=False)

      Update forgetting metric.
      See `Forgetting` for more detailed information.

      :param k: key to update
      :param v: value associated to k
      :param initial: update initial value. If False, update
          last value.


   .. method:: result(self, k=None) -> Union[float, None, Dict[int, float]]

      See `Forgetting` documentation for more detailed information.

      k: optional key from which compute forgetting.


   .. method:: before_training_exp(self, strategy: BaseStrategy) -> None

      Called before `train_exp` by the `BaseStrategy`. 


   .. method:: before_eval(self, strategy) -> None

      Called before `eval` by the `BaseStrategy`. 


   .. method:: before_eval_exp(self, strategy: BaseStrategy) -> None

      Called before `eval_exp` by the `BaseStrategy`. 


   .. method:: after_eval_iteration(self, strategy: BaseStrategy) -> None

      Called after the end of an iteration by the
      `BaseStrategy`. 


   .. method:: after_eval_exp(self, strategy: BaseStrategy) -> MetricResult

      Called after `eval_exp` by the `BaseStrategy`. 


   .. method:: metric_update(self, strategy)
      :abstractmethod:


   .. method:: metric_result(self, strategy)
      :abstractmethod:


   .. method:: __str__(self)
      :abstractmethod:

      Return str(self).



.. py:class:: ExperienceForgetting

   Bases: :class:`avalanche.evaluation.metrics.forgetting_bwt.GenericExperienceForgetting`

   The ExperienceForgetting metric, describing the accuracy loss
   detected for a certain experience.

   This plugin metric, computed separately for each experience,
   is the difference between the accuracy result obtained after
   first training on a experience and the accuracy result obtained
   on the same experience at the end of successive experiences.

   This metric is computed during the eval phase only.

   Creates an instance of the ExperienceForgetting metric.

   .. method:: metric_update(self, strategy)


   .. method:: metric_result(self, strategy)


   .. method:: __str__(self)

      Return str(self).



.. py:class:: GenericStreamForgetting

   Bases: :class:`avalanche.evaluation.metrics.forgetting_bwt.GenericExperienceForgetting`

   The GenericStreamForgetting metric, describing the average evaluation
   change in the desired metric detected over all experiences observed
   during training.

   In particular, the user should override:
   * __init__ by calling `super` and instantiating the `self.current_metric`
   property as a valid avalanche metric
   * `metric_update`, to update `current_metric`
   * `metric_result` to get the result from `current_metric`.
   * `__str__` to define the experience forgetting  name.

   This plugin metric, computed over all observed experiences during training,
   is the average over the difference between the metric result obtained
   after first training on a experience and the metric result obtained
   on the same experience at the end of successive experiences.

   This metric is computed during the eval phase only.

   Creates an instance of the GenericStreamForgetting metric.

   .. attribute:: stream_forgetting
      

      The average forgetting over all experiences


   .. method:: reset(self) -> None

      Resets the forgetting metrics.

      Beware that this will also reset the initial metric value of each
      experience!

      :return: None.


   .. method:: exp_update(self, k, v, initial=False)

      Update forgetting metric.
      See `Forgetting` for more detailed information.

      :param k: key to update
      :param v: value associated to k
      :param initial: update initial value. If False, update
          last value.


   .. method:: exp_result(self, k=None) -> Union[float, None, Dict[int, float]]

      Result for experience defined by a key.
      See `Forgetting` documentation for more detailed information.

      k: optional key from which compute forgetting.


   .. method:: result(self, k=None) -> Union[float, None, Dict[int, float]]

      The average forgetting over all experience.

      k: optional key from which compute forgetting.


   .. method:: before_eval(self, strategy) -> None

      Called before `eval` by the `BaseStrategy`. 


   .. method:: after_eval_exp(self, strategy: BaseStrategy) -> None

      Called after `eval_exp` by the `BaseStrategy`. 


   .. method:: after_eval(self, strategy: BaseStrategy) -> 'MetricResult'

      Called after `eval` by the `BaseStrategy`. 


   .. method:: metric_update(self, strategy)
      :abstractmethod:


   .. method:: metric_result(self, strategy)
      :abstractmethod:


   .. method:: __str__(self)
      :abstractmethod:

      Return str(self).



.. py:class:: StreamForgetting

   Bases: :class:`avalanche.evaluation.metrics.forgetting_bwt.GenericStreamForgetting`

   The StreamForgetting metric, describing the average evaluation accuracy loss
   detected over all experiences observed during training.

   This plugin metric, computed over all observed experiences during training,
   is the average over the difference between the accuracy result obtained
   after first training on a experience and the accuracy result obtained
   on the same experience at the end of successive experiences.

   This metric is computed during the eval phase only.

   Creates an instance of the StreamForgetting metric.

   .. method:: metric_update(self, strategy)


   .. method:: metric_result(self, strategy)


   .. method:: __str__(self)

      Return str(self).



.. py:class:: GenericTaskForgetting

   Bases: :class:`PluginMetric[Dict[int, float]]`

   The GenericTaskForgetting metric, describing the average evaluation
   change in the desired metric detected over all tasks observed
   during training and evaluation.

   In particular, the user should override:
   * __init__ by calling `super` and instantiating the
     `self.current_train_metric` and `current_eval_metric` properties as
     valid avalanche metrics (the same metric for both properties).
     The metric should be able to return values for each task separately.
   * `metric_update`, to update `current_metric`
   * `__str__` to define the experience forgetting  name.

   This plugin metric, computed over all observed experiences during training,
   is the average over the difference between the metric result obtained
   after first training on a experience and the metric result obtained
   on the same experience at the end of successive experiences.

   This metric is computed during the eval phase only.

   Creates an instance of a plugin metric.

   Child classes can safely invoke this (super) constructor as the first
   experience.

   .. method:: reset(self, **kwargs) -> None


   .. method:: result(self, **kwargs)


   .. method:: update(self, k, v, initial)


   .. method:: before_training(self, strategy: BaseStrategy)

      Called before `train` by the `BaseStrategy`. 


   .. method:: after_training_iteration(self, strategy: BaseStrategy)

      Called after the end of a training iteration by the
      `BaseStrategy`. 


   .. method:: before_eval(self, strategy: BaseStrategy)

      Called before `eval` by the `BaseStrategy`. 


   .. method:: after_eval_iteration(self, strategy: BaseStrategy)

      Called after the end of an iteration by the
      `BaseStrategy`. 


   .. method:: after_eval(self, strategy: BaseStrategy) -> 'MetricResult'

      Called after `eval` by the `BaseStrategy`. 


   .. method:: metric_update(self, strategy, train)
      :abstractmethod:


   .. method:: __str__(self)
      :abstractmethod:

      Return str(self).



.. py:class:: TaskForgetting

   Bases: :class:`avalanche.evaluation.metrics.forgetting_bwt.GenericTaskForgetting`

   The Task Forgetting metric returns the amount of forgetting
   on each task separately. The task-wise forgetting is computed
   as the difference between the average accuracy when last training
   on the task and the average accuracy when last evaluating on the same task.


   Creates an instance of a plugin metric.

   Child classes can safely invoke this (super) constructor as the first
   experience.

   .. method:: metric_update(self, strategy, train)


   .. method:: __str__(self)

      Return str(self).



.. function:: forgetting_metrics(*, experience=False, stream=False, task=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param experience: If True, will return a metric able to log
       the forgetting on each evaluation experience.
   :param stream: If True, will return a metric able to log
       the forgetting averaged over the evaluation stream experiences,
       which have been observed during training.
   :param task: If True, will return a metric able to log the forgetting
       across each task encountered during training and evaluation.

   :return: A list of plugin metrics.


.. py:class:: BWT

   Bases: :class:`avalanche.evaluation.metrics.forgetting_bwt.Forgetting`

   The standalone Backward Transfer metric.
   This metric returns the backward transfer relative to a specific key.
   Alternatively, this metric returns a dict in which each key is associated
   to the backward transfer.
   Backward transfer is computed as the difference between the last value
   recorded for a specific key and the first value recorded for that key.
   The value associated to a key can be update with the `update` method.

   At initialization, this metric returns an empty dictionary.

   Creates an instance of the standalone Forgetting metric

   .. method:: result(self, k=None) -> Union[float, None, Dict[int, float]]

      Backward Transfer is returned only for keys encountered twice.
      Backward Transfer is the negative forgetting.

      :param k: the key for which returning backward transfer. If k has not
          updated at least twice it returns None. If k is None,
          backward transfer will be returned for all keys encountered at
          least twice.

      :return: the difference between the last value encountered for k
          and its first value, if k is not None.
          It returns None if k has not been updated
          at least twice. If k is None, returns a dictionary
          containing keys whose value has been updated at least twice. The
          associated value is the difference between the last and first
          value recorded for that key.



.. py:class:: ExperienceBWT

   Bases: :class:`avalanche.evaluation.metrics.forgetting_bwt.ExperienceForgetting`

   The Experience Backward Transfer metric.

   This plugin metric, computed separately for each experience,
   is the difference between the last accuracy result obtained on a certain
   experience and the accuracy result obtained when first training on that
   experience.

   This metric is computed during the eval phase only.

   Creates an instance of the ExperienceForgetting metric.

   .. method:: result(self, k=None) -> Union[float, None, Dict[int, float]]

      See `Forgetting` documentation for more detailed information.

      k: optional key from which compute forgetting.


   .. method:: __str__(self)

      Return str(self).



.. py:class:: StreamBWT

   Bases: :class:`avalanche.evaluation.metrics.forgetting_bwt.StreamForgetting`

   The StreamBWT metric, emitting the average BWT across all experiences
   encountered during training.

   This plugin metric, computed over all observed experiences during training,
   is the average over the difference between the last accuracy result
   obtained on an experience and the accuracy result obtained when first
   training on that experience.

   This metric is computed during the eval phase only.

   Creates an instance of the StreamForgetting metric.

   .. method:: exp_result(self, k=None) -> Union[float, None, Dict[int, float]]

      Result for experience defined by a key.
      See `BWT` documentation for more detailed information.

      k: optional key from which compute backward transfer.


   .. method:: __str__(self)

      Return str(self).



.. py:class:: TaskBWT

   Bases: :class:`avalanche.evaluation.metrics.forgetting_bwt.TaskForgetting`

   The TaskBWT metric, emitting the average BWT task-wise.

   This plugin metric, computed over all observed tasks during training,
   is the average over the difference between the last accuracy result
   obtained on a task and the accuracy result obtained when last
   training on that task.

   This metric is computed during the eval phase only.

   Creates an instance of a plugin metric.

   Child classes can safely invoke this (super) constructor as the first
   experience.

   .. method:: result(self) -> Union[float, None, Dict[int, float]]

      Result for experience defined by a key.
      See `BWT` documentation for more detailed information.


   .. method:: __str__(self)

      Return str(self).



.. function:: bwt_metrics(*, experience=False, stream=False, task=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param experience: If True, will return a metric able to log
       the backward transfer on each evaluation experience.
   :param stream: If True, will return a metric able to log
       the backward transfer averaged over the evaluation stream experiences
       which have been observed during training.
   :param task: If True, will return a metric able to log
       the backward transfer for each task in the evaluation stream
   :return: A list of plugin metrics.


