:mod:`avalanche.evaluation.metrics.forgetting`
==============================================

.. py:module:: avalanche.evaluation.metrics.forgetting


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.forgetting.Forgetting
   avalanche.evaluation.metrics.forgetting.ExperienceForgetting
   avalanche.evaluation.metrics.forgetting.StreamForgetting



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.forgetting.forgetting_metrics


.. py:class:: Forgetting

   Bases: :class:`Metric[Union[float, None, Dict[int, float]]]`

   The standalone Forgetting metric.
   This metric returns the forgetting relative to a specific key.
   Alternatively, this metric returns a dict in which each key is associated
   to the forgetting.
   Forgetting is computed as the difference between the first value recorded
   for a specific key and the last value recorded for that key.
   The value associated to a key can be update with the `update` method.

   At initialization, this metric returns an empty dictionary.

   Creates an instance of the standalone Forgetting metric

   .. attribute:: initial
      :annotation: :Dict[int, float]

      The initial value for each key.


   .. attribute:: last
      :annotation: :Dict[int, float]

      The last value detected for each key


   .. method:: update_initial(self, k, v)


   .. method:: update_last(self, k, v)


   .. method:: update(self, k, v, initial=False)


   .. method:: result(self, k=None) -> Union[float, None, Dict[int, float]]

      Forgetting is returned only for keys encountered twice.

      :param k: the key for which returning forgetting. If k has not
          updated at least twice it returns None. If k is None,
          forgetting will be returned for all keys encountered at least
          twice.

      :return: the difference between the first and last value encountered
          for k, if k is not None. It returns None if k has not been updated
          at least twice. If k is None, returns a dictionary
          containing keys whose value has been updated at least twice. The
          associated value is the difference between the first and last
          value recorded for that key.


   .. method:: reset_last(self) -> None


   .. method:: reset(self) -> None

      Resets the metric internal state.

      :return: None.



.. py:class:: ExperienceForgetting

   Bases: :class:`PluginMetric[Dict[int, float]]`

   The ExperienceForgetting metric, describing the accuracy loss
   detected for a certain experience.

   This plugin metric, computed separately for each experience,
   is the difference between the accuracy result obtained after
   first training on a experience and the accuracy result obtained
   on the same experience at the end of successive experiences.

   This metric is computed during the eval phase only.

   Creates an instance of the ExperienceForgetting metric.

   .. attribute:: forgetting
      

      The general metric to compute forgetting


   .. attribute:: eval_exp_id
      

      The current evaluation experience id


   .. attribute:: train_exp_id
      

      The last encountered training experience id


   .. method:: reset(self) -> None

      Resets the metric.

      Beware that this will also reset the initial accuracy of each
      experience!

      :return: None.


   .. method:: reset_last_accuracy(self) -> None

      Resets the last accuracy.

      This will preserve the initial accuracy value of each experience.
      To be used at the beginning of each eval experience.

      :return: None.


   .. method:: update(self, k, v, initial=False)

      Update forgetting metric.
      See `Forgetting` for more detailed information.

      :param k: key to update
      :param v: value associated to k
      :param initial: update initial value. If False, update
          last value.


   .. method:: result(self, k=None) -> Union[float, None, Dict[int, float]]

      See `Forgetting` documentation for more detailed information.

      k: optional key from which compute forgetting.


   .. method:: before_training_exp(self, strategy: BaseStrategy) -> None

      Called before `train_exp` by the `BaseStrategy`. 


   .. method:: before_eval(self, strategy) -> None

      Called before `eval` by the `BaseStrategy`. 


   .. method:: before_eval_exp(self, strategy: BaseStrategy) -> None

      Called before `eval_exp` by the `BaseStrategy`. 


   .. method:: after_eval_iteration(self, strategy: BaseStrategy) -> None

      Called after the end of an iteration by the
      `BaseStrategy`. 


   .. method:: after_eval_exp(self, strategy: BaseStrategy) -> MetricResult

      Called after `eval_exp` by the `BaseStrategy`. 


   .. method:: __str__(self)

      Return str(self).



.. py:class:: StreamForgetting

   Bases: :class:`PluginMetric[Dict[int, float]]`

   The StreamForgetting metric, describing the average evaluation accuracy loss
   detected over all experiences observed during training.

   This plugin metric, computed over all observed experiences during training,
   is the average over the difference between the accuracy result obtained
   after first training on a experience and the accuracy result obtained
   on the same experience at the end of successive experiences.

   This metric is computed during the eval phase only.

   Creates an instance of the StreamForgetting metric.

   .. attribute:: stream_forgetting
      

      The average forgetting over all experiences


   .. attribute:: forgetting
      

      The general metric to compute forgetting


   .. attribute:: eval_exp_id
      

      The current evaluation experience id


   .. attribute:: train_exp_id
      

      The last encountered training experience id


   .. method:: reset(self) -> None

      Resets the forgetting metrics.

      Beware that this will also reset the initial accuracy of each
      experience!

      :return: None.


   .. method:: reset_last_accuracy(self) -> None

      Resets the last accuracy.

      This will preserve the initial accuracy value of each experience.
      To be used at the beginning of each eval experience.

      :return: None.


   .. method:: exp_update(self, k, v, initial=False)

      Update forgetting metric.
      See `Forgetting` for more detailed information.

      :param k: key to update
      :param v: value associated to k
      :param initial: update initial value. If False, update
          last value.


   .. method:: exp_result(self, k=None) -> Union[float, None, Dict[int, float]]

      Result for experience defined by a key.
      See `Forgetting` documentation for more detailed information.

      k: optional key from which compute forgetting.


   .. method:: result(self, k=None) -> Union[float, None, Dict[int, float]]

      The average forgetting over all experience.

      k: optional key from which compute forgetting.


   .. method:: before_training_exp(self, strategy: BaseStrategy) -> None

      Called before `train_exp` by the `BaseStrategy`. 


   .. method:: before_eval(self, strategy) -> None

      Called before `eval` by the `BaseStrategy`. 


   .. method:: before_eval_exp(self, strategy: BaseStrategy) -> None

      Called before `eval_exp` by the `BaseStrategy`. 


   .. method:: after_eval_iteration(self, strategy: BaseStrategy) -> None

      Called after the end of an iteration by the
      `BaseStrategy`. 


   .. method:: after_eval_exp(self, strategy: BaseStrategy) -> None

      Called after `eval_exp` by the `BaseStrategy`. 


   .. method:: after_eval(self, strategy: BaseStrategy) -> 'MetricResult'

      Called after `eval` by the `BaseStrategy`. 


   .. method:: __str__(self)

      Return str(self).



.. function:: forgetting_metrics(*, experience=False, stream=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param experience: If True, will return a metric able to log
       the forgetting on each evaluation experience.
   :param stream: If True, will return a metric able to log
       the forgetting averaged over the evaluation stream experiences,
       which have been observed during training.

   :return: A list of plugin metrics.


