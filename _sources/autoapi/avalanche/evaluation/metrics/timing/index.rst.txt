:mod:`avalanche.evaluation.metrics.timing`
==========================================

.. py:module:: avalanche.evaluation.metrics.timing


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.timing.ElapsedTime
   avalanche.evaluation.metrics.timing.MinibatchTime
   avalanche.evaluation.metrics.timing.EpochTime
   avalanche.evaluation.metrics.timing.RunningEpochTime
   avalanche.evaluation.metrics.timing.ExperienceTime
   avalanche.evaluation.metrics.timing.StreamTime



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.timing.timing_metrics


.. py:class:: ElapsedTime

   Bases: :class:`Metric[float]`

   The standalone Elapsed Time metric.

   Instances of this metric keep track of the time elapsed between calls to the
   `update` method. The starting time is set when the `update` method is called
   for the first time. That is, the starting time is *not* taken at the time
   the constructor is invoked.

   Calling the `update` method more than twice will update the metric to the
   elapsed time between the first and the last call to `update`.

   The result, obtained using the `result` method, is the time, in seconds,
   computed as stated above.

   The `reset` method will set the metric to its initial state, thus resetting
   the initial time. This metric in its initial state (or if the `update`
   method was invoked only once) will return an elapsed time of 0.

   Creates an instance of the ElapsedTime metric.

   This metric in its initial state (or if the `update` method was invoked
   only once) will return an elapsed time of 0. The metric can be updated
   by using the `update` method while the running accuracy can be retrieved
   using the `result` method.

   .. method:: update(self) -> None

      Update the elapsed time.

      For more info on how to set the initial time see the class description.

      :return: None.


   .. method:: result(self) -> float

      Retrieves the elapsed time.

      Calling this method will not change the internal state of the metric.

      :return: The elapsed time, in seconds, as a float value.


   .. method:: reset(self) -> None

      Resets the metric, including the initial time.

      :return: None.



.. py:class:: MinibatchTime

   Bases: :class:`avalanche.evaluation.metrics.timing.TimePluginMetric`

   The minibatch time metric.
   This plugin metric only works at training time.

   This metric "logs" the elapsed time for each iteration.

   If a more coarse-grained logging is needed, consider using
   :class:`EpochTime`.

   Creates an instance of the minibatch time metric.

   .. method:: before_training_iteration(self, strategy) -> MetricResult


   .. method:: __str__(self)



.. py:class:: EpochTime

   Bases: :class:`avalanche.evaluation.metrics.timing.TimePluginMetric`

   The epoch elapsed time metric.
   This plugin metric only works at training time.

   The elapsed time will be logged after each epoch.

   Creates an instance of the epoch time metric.

   .. method:: before_training_epoch(self, strategy) -> MetricResult


   .. method:: __str__(self)



.. py:class:: RunningEpochTime

   Bases: :class:`avalanche.evaluation.metrics.timing.TimePluginMetric`

   The running epoch time metric.
   This plugin metric only works at training time.

   For each iteration, this metric logs the average time
   between the start of the
   epoch and the current iteration.

   Creates an instance of the running epoch time metric..

   .. method:: before_training_epoch(self, strategy) -> MetricResult


   .. method:: after_training_iteration(self, strategy: BaseStrategy) -> MetricResult


   .. method:: result(self) -> float


   .. method:: __str__(self)



.. py:class:: ExperienceTime

   Bases: :class:`avalanche.evaluation.metrics.timing.TimePluginMetric`

   The experience time metric.
   This plugin metric only works at eval time.

   After each experience, this metric emits the average time of that
   experience.

   Creates an instance of the experience time metric.

   .. method:: before_eval_exp(self, strategy: BaseStrategy) -> MetricResult


   .. method:: __str__(self)



.. py:class:: StreamTime

   Bases: :class:`avalanche.evaluation.metrics.timing.TimePluginMetric`

   The stream time metric.
   This metric only works at eval time.

   After the entire evaluation stream,
   this plugin metric emits the average time of that stream.

   Creates an instance of the stream time metric.

   .. method:: before_eval(self, strategy: BaseStrategy) -> MetricResult


   .. method:: __str__(self)



.. function:: timing_metrics(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param minibatch: If True, will return a metric able to log the train
       minibatch elapsed time.
   :param epoch: If True, will return a metric able to log the train epoch
       elapsed time.
   :param epoch_running: If True, will return a metric able to log the running
       train epoch elapsed time.
   :param experience: If True, will return a metric able to log the eval
       experience elapsed time.
   :param stream: If True, will return a metric able to log the eval stream
       elapsed time.

   :return: A list of plugin metrics.


