:mod:`avalanche.evaluation.metrics.confusion_matrix`
====================================================

.. py:module:: avalanche.evaluation.metrics.confusion_matrix


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.confusion_matrix.ConfusionMatrix
   avalanche.evaluation.metrics.confusion_matrix.StreamConfusionMatrix



.. py:class:: ConfusionMatrix(num_classes: int = None, normalize: Literal['true', 'pred', 'all'] = None)

   Bases: :class:`Metric[Tensor]`

   The standalone confusion matrix metric.

   Instances of this metric keep track of the confusion matrix by receiving a
   pair of "ground truth" and "prediction" Tensors describing the labels of a
   minibatch. Those two tensors can both contain plain labels or
   one-hot/logit vectors.

   The result is the unnormalized running confusion matrix.

   Beware that by default the confusion matrix size will depend on the value of
   the maximum label as detected by looking at both the ground truth and
   predictions Tensors. When passing one-hot/logit vectors, this
   metric will try to infer the number of classes from the vector sizes.
   Otherwise, the maximum label value encountered in the truth/prediction
   Tensors will be used.

   If the user sets the `num_classes`, then the confusion matrix will always be
   of size `num_classes, num_classes`. Whenever a prediction or label tensor is
   provided as logits, only the first `num_classes` units will be considered in
   the confusion matrix computation. If they are provided as numerical labels,
   each of them has to be smaller than `num_classes`.

   The reset method will bring the metric to its initial state. By default
   this metric in its initial state will return an empty Tensor.

   Creates an instance of the standalone confusion matrix metric.

   By default this metric in its initial state will return an empty Tensor.
   The metric can be updated by using the `update` method while the running
   confusion matrix can be retrieved using the `result` method.

   :param num_classes: The number of classes. Defaults to None,
       which means that the number of classes will be inferred from
       ground truth and prediction Tensors (see class description for more
       details). If not None, the confusion matrix will always be of size
       `num_classes, num_classes` and only the first `num_classes` values
       of output logits or target logits will be considered in the update.
       If the output or targets are provided as numerical labels,
       there can be no label greater than `num_classes`.
   :param normalize: how to normalize confusion matrix.
       None to not normalize

   .. method:: update(self, true_y: Tensor, predicted_y: Tensor) -> None

      Update the running confusion matrix given the true and predicted labels.

      :param true_y: The ground truth. Both labels and one-hot vectors
          are supported.
      :param predicted_y: The ground truth. Both labels and logit vectors
          are supported.
      :return: None.


   .. method:: result(self) -> Tensor

      Retrieves the unnormalized confusion matrix.

      Calling this method will not change the internal state of the metric.

      :return: The running confusion matrix, as a Tensor.


   .. method:: reset(self) -> None

      Resets the metric.

      Calling this method will *not* reset the default number of classes
      optionally defined in the constructor optional parameter.

      :return: None.


   .. method:: nan_to_num(matrix: Tensor) -> Tensor
      :staticmethod:



.. py:class:: StreamConfusionMatrix(num_classes: Union[int, Mapping[int, int]] = None, normalize: Literal['true', 'pred', 'all'] = None, save_image: bool = True, image_creator: Callable[[Tensor], Image] = default_cm_image_creator)

   Bases: :class:`PluginMetric[Tensor]`

   The Stream Confusion Matrix metric.
   This plugin metric only works on the eval phase.

   Confusion Matrix computation can be slow if you compute it for a large
   number of classes. We recommend to set `save_image=False` if the runtime
   is too large.

   At the end of the eval phase, this metric logs the confusion matrix
   relative to all the patterns seen during eval.

   The metric can log either a Tensor or a PIL Image representing the
   confusion matrix.

   Creates an instance of the Stream Confusion Matrix metric.

   We recommend to set `save_image=False` if the runtime is too large.
   In fact, a large number of classes may increase the computation time
   of this metric.

   :param num_classes: The number of classes. Defaults to None,
       which means that the number of classes will be inferred from
       ground truth and prediction Tensors (see class description for more
       details). If not None, the confusion matrix will always be of size
       `num_classes, num_classes` and only the first `num_classes` values
       of output logits or target logits will be considered in the update.
       If the output or targets are provided as numerical labels,
       there can be no label greater than `num_classes`.
   :param normalize: Normalizes confusion matrix over the true (rows),
       predicted (columns) conditions or all the population. If None,
       confusion matrix will not be normalized. Valid values are: 'true',
       'pred' and 'all' or None.
   :param save_image: If True, a graphical representation of the confusion
       matrix will be logged, too. If False, only the Tensor representation
       will be logged. Defaults to True.
   :param image_creator: A callable that, given the tensor representation
       of the confusion matrix, returns a graphical representation of the
       matrix as a PIL Image. Defaults to `default_cm_image_creator`.

   .. method:: reset(self) -> None


   .. method:: result(self) -> Tensor


   .. method:: update(self, true_y: Tensor, predicted_y: Tensor) -> None


   .. method:: before_eval(self, strategy) -> None

      Called before `eval` by the `BaseStrategy`. 


   .. method:: after_eval_iteration(self, strategy: BaseStrategy) -> None

      Called after the end of an iteration by the
      `BaseStrategy`. 


   .. method:: after_eval(self, strategy: BaseStrategy) -> MetricResult

      Called after `eval` by the `BaseStrategy`. 


   .. method:: __str__(self)

      Return str(self).



