:mod:`avalanche.training.plugins.evaluation`
============================================

.. py:module:: avalanche.training.plugins.evaluation


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.plugins.evaluation.EvaluationPlugin



.. py:class:: EvaluationPlugin(*metrics: Union['PluginMetric', Sequence['PluginMetric']], loggers: Union['StrategyLogger', Sequence['StrategyLogger']] = None, collect_all=True, benchmark=None, strict_checks=False)

   Bases: :class:`avalanche.training.plugins.strategy_plugin.StrategyPlugin`

   An evaluation plugin that obtains relevant data from the
   training and eval loops of the strategy through callbacks.
   The plugin keeps a dictionary with the last recorded value for each metric.
   The dictionary will be returned by the `train` and `eval` methods of the
   strategies.
   It is also possible to keep a dictionary with all recorded metrics by
   specifying `collect_all=True`. The dictionary can be retrieved via
   the `get_all_metrics` method.

   This plugin also logs metrics using the provided loggers.

   Creates an instance of the evaluation plugin.

   :param metrics: The metrics to compute.
   :param loggers: The loggers to be used to log the metric values.
   :param collect_all: if True, collect in a separate dictionary all
       metric curves values. This dictionary is accessible with
       `get_all_metrics` method.
   :param benchmark: continual learning benchmark needed to check stream
       completeness during evaluation or other kind of properties. If
       None, no check will be conducted and the plugin will emit a
       warning to signal this fact.
   :param strict_checks: if True, `benchmark` has to be provided.
       In this case, only full evaluation streams are admitted when
       calling `eval`. An error will be raised otherwise. When False,
       `benchmark` can be `None` and only warnings will be raised.

   .. method:: active(self)
      :property:


   .. method:: get_last_metrics(self)

      Return a shallow copy of dictionary with metric names
      as keys and last metrics value as values.

      :return: a dictionary with full metric
          names as keys and last metric value as value.


   .. method:: get_all_metrics(self)

      Return the dictionary of all collected metrics.
      This method should be called only when `collect_all` is set to True.

      :return: if `collect_all` is True, returns a dictionary
          with full metric names as keys and a tuple of two lists
          as value. The first list gathers x values (indices
          representing time steps at which the corresponding
          metric value has been emitted). The second list
          gathers metric values. a dictionary. If `collect_all`
          is False return an empty dictionary


   .. method:: reset_last_metrics(self)

      Set the dictionary storing last value for each metric to be
      empty dict.


   .. method:: before_training(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_training_exp(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_train_dataset_adaptation(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_train_dataset_adaptation(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_training_epoch(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_training_iteration(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_forward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_forward(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_backward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_backward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_training_iteration(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_update(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_update(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_training_epoch(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_training_exp(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_training(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval_dataset_adaptation(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval_dataset_adaptation(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval_exp(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval_exp(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval_iteration(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval_forward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval_forward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval_iteration(self, strategy: BaseStrategy, **kwargs)



.. data:: default_logger
   

   

