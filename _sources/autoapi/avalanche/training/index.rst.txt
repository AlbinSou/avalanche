:mod:`avalanche.training`
=========================

.. py:module:: avalanche.training

.. autoapi-nested-parse::

   The :py:mod:`training` module provides a generic continual learning training
   class (:py:class:`BaseStrategy`) and implementations of the most common
   CL strategies. These are provided either as standalone strategies in
   :py:mod:`training.strategies` or as plugins (:py:mod:`training.plugins`) that
   can be easily combined with your own strategy.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   plugins/index.rst
   strategies/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.training.InteractiveLogger
   avalanche.training.EvaluationPlugin



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.training.accuracy_metrics
   avalanche.training.loss_metrics


.. function:: accuracy_metrics(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param minibatch: If True, will return a metric able to log
       the minibatch accuracy at training time.
   :param epoch: If True, will return a metric able to log
       the epoch accuracy at training time.
   :param epoch_running: If True, will return a metric able to log
       the running epoch accuracy at training time.
   :param experience: If True, will return a metric able to log
       the accuracy on each evaluation experience.
   :param stream: If True, will return a metric able to log
       the accuracy averaged over the entire evaluation stream of experiences.

   :return: A list of plugin metrics.


.. function:: loss_metrics(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param minibatch: If True, will return a metric able to log
       the minibatch loss at training time.
   :param epoch: If True, will return a metric able to log
       the epoch loss at training time.
   :param epoch_running: If True, will return a metric able to log
       the running epoch loss at training time.
   :param experience: If True, will return a metric able to log
       the loss on each evaluation experience.
   :param stream: If True, will return a metric able to log
       the loss averaged over the entire evaluation stream of experiences.

   :return: A list of plugin metrics.


.. py:class:: InteractiveLogger

   Bases: :class:`avalanche.logging.TextLogger`

   The `InteractiveLogger` class provides logging facilities
   for the console standard output. The logger shows
   a progress bar during training and evaluation flows and
   interactively display metric results as soon as they
   become available. The logger writes metric results after
   each training epoch, evaluation experience and at the
   end of the entire evaluation stream.

   .. note::
       To avoid an excessive amount of printed lines,
       this logger will **not** print results after
       each iteration. If the user is monitoring
       metrics which emit results after each minibatch
       (e.g., `MinibatchAccuracy`), only the last recorded
       value of such metrics will be reported at the end
       of the epoch.

   .. note::
       Since this logger works on the standard output,
       metrics producing images or more complex visualizations
       will be converted to a textual format suitable for
       console printing. You may want to add more loggers
       to your `EvaluationPlugin` to better support
       different formats.

   Creates an instance of `TextLogger` class.

   :param file: destination file to which print metrics
       (default=sys.stdout).

   .. method:: before_training_epoch(self, strategy: BaseStrategy, metric_values: List['MetricValue'], **kwargs)

      Called before `train_epoch` by the `BaseStrategy`. 


   .. method:: after_training_epoch(self, strategy: BaseStrategy, metric_values: List['MetricValue'], **kwargs)

      Called after `train_epoch` by the `BaseStrategy`. 


   .. method:: before_eval_exp(self, strategy: BaseStrategy, metric_values: List['MetricValue'], **kwargs)

      Called before `eval_exp` by the `BaseStrategy`. 


   .. method:: after_eval_exp(self, strategy: BaseStrategy, metric_values: List['MetricValue'], **kwargs)

      Called after `eval_exp` by the `BaseStrategy`. 


   .. method:: after_training_iteration(self, strategy: BaseStrategy, metric_values: List['MetricValue'], **kwargs)

      Called after the end of a training iteration by the
      `BaseStrategy`. 


   .. method:: after_eval_iteration(self, strategy: BaseStrategy, metric_values: List['MetricValue'], **kwargs)

      Called after the end of an iteration by the
      `BaseStrategy`. 



.. py:class:: EvaluationPlugin(*metrics: Union['PluginMetric', Sequence['PluginMetric']], loggers: Union['StrategyLogger', Sequence['StrategyLogger']] = None, collect_all=True)

   Bases: :class:`avalanche.training.plugins.strategy_plugin.StrategyPlugin`

   An evaluation plugin that obtains relevant data from the
   training and eval loops of the strategy through callbacks.
   The plugin keeps a dictionary with the last recorded value for each metric.
   The dictionary will be returned by the `train` and `eval` methods of the
   strategies.
   It is also possible to keep a dictionary with all recorded metrics by
   specifying `collect_all=True`. The dictionary can be retrieved via
   the `get_all_metrics` method.

   This plugin also logs metrics using the provided loggers.

   Creates an instance of the evaluation plugin.

   :param metrics: The metrics to compute.
   :param loggers: The loggers to be used to log the metric values.
   :param collect_all: if True, collect in a separate dictionary all
       metric curves values. This dictionary is accessible with
       `get_all_metrics` method.

   .. method:: get_last_metrics(self)

      Return a shallow copy of dictionary with metric names
      as keys and last metrics value as values.

      :return: a dictionary with full metric
          names as keys and last metric value as value.


   .. method:: get_all_metrics(self)

      Return the dictionary of all collected metrics.
      This method should be called only when `collect_all` is set to True.

      :return: if `collect_all` is True, returns a dictionary
          with full metric names as keys and a tuple of two lists
          as value. The first list gathers x values (indices
          representing time steps at which the corresponding
          metric value has been emitted). The second list
          gathers metric values. a dictionary. If `collect_all`
          is False return an empty dictionary


   .. method:: reset_last_metrics(self)

      Set the dictionary storing last value for each metric to be
      empty dict.


   .. method:: before_training(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_training_exp(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_train_dataset_adaptation(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_train_dataset_adaptation(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_training_epoch(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_training_iteration(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_forward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_forward(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_backward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_backward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_training_iteration(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_update(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_update(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_training_epoch(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_training_exp(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_training(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval_dataset_adaptation(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval_dataset_adaptation(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval_exp(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval_exp(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval_iteration(self, strategy: BaseStrategy, **kwargs)


   .. method:: before_eval_forward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval_forward(self, strategy: BaseStrategy, **kwargs)


   .. method:: after_eval_iteration(self, strategy: BaseStrategy, **kwargs)



.. data:: default_logger
   

   

