

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>avalanche.evaluation.metrics &mdash; Avalanche 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/mystyle.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../search/" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../">
          

          
            
            <img src="../../../../_static/avalanche_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../benchmarks/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../logging/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.logging</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../models/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.models</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#submodules">Submodules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../core/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.core</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../#functions">Functions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../">Avalanche</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../" class="icon icon-home"></a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../_sources/autoapi/avalanche/evaluation/metrics/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-avalanche.evaluation.metrics">
<span id="avalanche-evaluation-metrics"></span><h1><a class="reference internal" href="#module-avalanche.evaluation.metrics" title="avalanche.evaluation.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics</span></code></a><a class="headerlink" href="#module-avalanche.evaluation.metrics" title="Permalink to this headline">¶</a></h1>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">metrics</span></code> module provides a set of already
implemented metrics, ready to be used both standalone
and together with the <cite>EvaluationPlugin</cite>.
To use a standalone metric, please use the class which
inherits from <cite>Metric</cite> and manually call the appropriate
<cite>update</cite>, <cite>reset</cite> and ‘result` method.
To automatically monitor metrics during training and evaluation
flows, specific classes which inherit from <cite>PluginMetric</cite>
are provided. Most of these metrics can be created by leveraging
the related helper function. Such function instantiates the same
metric monitored on multiple callbacks (after each epoch, minibatch
or experience). For example, to print accuracy metrics at the
end of each training epoch and at the end of each evaluation experience,
it is only required to call <cite>accuracy_metrics(epoch=True, experience=True)</cite>
when creating the <cite>EvaluationPlugin</cite>.</p>
<p>When available, please always use helper functions to specify
the metrics to be monitored.</p>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="accuracy/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="confusion_matrix/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.confusion_matrix</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu_usage/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.cpu_usage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="disk_usage/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.disk_usage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="forgetting/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.forgetting</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu_usage/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.gpu_usage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="loss/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.loss</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="mac/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.mac</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="mean/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.mean</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="ram_usage/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.ram_usage</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="timing/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.timing</span></code></a></li>
</ul>
</div>
</div>
<div class="section" id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Mean" title="avalanche.evaluation.metrics.Mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Mean</span></code></a></p></td>
<td><p>The standalone mean metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Sum" title="avalanche.evaluation.metrics.Sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Sum</span></code></a></p></td>
<td><p>The standalone sum metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Accuracy" title="avalanche.evaluation.metrics.Accuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Accuracy</span></code></a></p></td>
<td><p>The Accuracy metric. This is a standalone metric</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchAccuracy" title="avalanche.evaluation.metrics.MinibatchAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchAccuracy</span></code></a></p></td>
<td><p>The minibatch plugin accuracy metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochAccuracy" title="avalanche.evaluation.metrics.EpochAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a></p></td>
<td><p>The average accuracy over a single training epoch.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RunningEpochAccuracy" title="avalanche.evaluation.metrics.RunningEpochAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochAccuracy</span></code></a></p></td>
<td><p>The average accuracy across all minibatches up to the current</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceAccuracy" title="avalanche.evaluation.metrics.ExperienceAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceAccuracy</span></code></a></p></td>
<td><p>At the end of each experience, this plugin metric reports</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamAccuracy" title="avalanche.evaluation.metrics.StreamAccuracy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamAccuracy</span></code></a></p></td>
<td><p>At the end of the entire stream of experiences, this plugin metric</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ConfusionMatrix" title="avalanche.evaluation.metrics.ConfusionMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConfusionMatrix</span></code></a></p></td>
<td><p>The standalone confusion matrix metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamConfusionMatrix" title="avalanche.evaluation.metrics.StreamConfusionMatrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamConfusionMatrix</span></code></a></p></td>
<td><p>The Stream Confusion Matrix metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.CPUUsage" title="avalanche.evaluation.metrics.CPUUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CPUUsage</span></code></a></p></td>
<td><p>The standalone CPU usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchCPUUsage" title="avalanche.evaluation.metrics.MinibatchCPUUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchCPUUsage</span></code></a></p></td>
<td><p>The minibatch CPU usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochCPUUsage" title="avalanche.evaluation.metrics.EpochCPUUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochCPUUsage</span></code></a></p></td>
<td><p>The Epoch CPU usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage" title="avalanche.evaluation.metrics.RunningEpochCPUUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochCPUUsage</span></code></a></p></td>
<td><p>The running epoch CPU usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceCPUUsage" title="avalanche.evaluation.metrics.ExperienceCPUUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceCPUUsage</span></code></a></p></td>
<td><p>The average experience CPU usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamCPUUsage" title="avalanche.evaluation.metrics.StreamCPUUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamCPUUsage</span></code></a></p></td>
<td><p>The average stream CPU usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.DiskUsage" title="avalanche.evaluation.metrics.DiskUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DiskUsage</span></code></a></p></td>
<td><p>The standalone disk usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchDiskUsage" title="avalanche.evaluation.metrics.MinibatchDiskUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchDiskUsage</span></code></a></p></td>
<td><p>The minibatch Disk usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochDiskUsage" title="avalanche.evaluation.metrics.EpochDiskUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochDiskUsage</span></code></a></p></td>
<td><p>The Epoch Disk usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceDiskUsage" title="avalanche.evaluation.metrics.ExperienceDiskUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceDiskUsage</span></code></a></p></td>
<td><p>The average experience Disk usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamDiskUsage" title="avalanche.evaluation.metrics.StreamDiskUsage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamDiskUsage</span></code></a></p></td>
<td><p>The average stream Disk usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Forgetting" title="avalanche.evaluation.metrics.Forgetting"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Forgetting</span></code></a></p></td>
<td><p>The standalone Forgetting metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceForgetting" title="avalanche.evaluation.metrics.ExperienceForgetting"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceForgetting</span></code></a></p></td>
<td><p>The ExperienceForgetting metric, describing the accuracy loss</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamForgetting" title="avalanche.evaluation.metrics.StreamForgetting"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamForgetting</span></code></a></p></td>
<td><p>The StreamForgetting metric, describing the average evaluation accuracy loss</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MaxGPU" title="avalanche.evaluation.metrics.MaxGPU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MaxGPU</span></code></a></p></td>
<td><p>The standalone GPU usage metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchMaxGPU" title="avalanche.evaluation.metrics.MinibatchMaxGPU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchMaxGPU</span></code></a></p></td>
<td><p>The Minibatch Max GPU metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochMaxGPU" title="avalanche.evaluation.metrics.EpochMaxGPU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochMaxGPU</span></code></a></p></td>
<td><p>The Epoch Max GPU metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceMaxGPU" title="avalanche.evaluation.metrics.ExperienceMaxGPU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceMaxGPU</span></code></a></p></td>
<td><p>The Experience Max GPU metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamMaxGPU" title="avalanche.evaluation.metrics.StreamMaxGPU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamMaxGPU</span></code></a></p></td>
<td><p>The Stream Max GPU metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.Loss" title="avalanche.evaluation.metrics.Loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Loss</span></code></a></p></td>
<td><p>The standalone Loss metric. This is a general metric</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchLoss" title="avalanche.evaluation.metrics.MinibatchLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchLoss</span></code></a></p></td>
<td><p>The minibatch loss metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochLoss" title="avalanche.evaluation.metrics.EpochLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochLoss</span></code></a></p></td>
<td><p>The average loss over a single training epoch.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RunningEpochLoss" title="avalanche.evaluation.metrics.RunningEpochLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochLoss</span></code></a></p></td>
<td><p>The average loss across all minibatches up to the current</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceLoss" title="avalanche.evaluation.metrics.ExperienceLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceLoss</span></code></a></p></td>
<td><p>At the end of each experience, this metric reports</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamLoss" title="avalanche.evaluation.metrics.StreamLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamLoss</span></code></a></p></td>
<td><p>At the end of the entire stream of experiences, this metric reports the</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MAC" title="avalanche.evaluation.metrics.MAC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MAC</span></code></a></p></td>
<td><p>Standalone Multiply-and-accumulate metric. Provides a lower bound of the</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchMAC" title="avalanche.evaluation.metrics.MinibatchMAC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchMAC</span></code></a></p></td>
<td><p>The minibatch MAC metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochMAC" title="avalanche.evaluation.metrics.EpochMAC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochMAC</span></code></a></p></td>
<td><p>The MAC at the end of each epoch computed on a</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceMAC" title="avalanche.evaluation.metrics.ExperienceMAC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceMAC</span></code></a></p></td>
<td><p>At the end of each experience, this metric reports the</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MaxRAM" title="avalanche.evaluation.metrics.MaxRAM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MaxRAM</span></code></a></p></td>
<td><p>The standalone RAM usage metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchMaxRAM" title="avalanche.evaluation.metrics.MinibatchMaxRAM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchMaxRAM</span></code></a></p></td>
<td><p>The Minibatch Max RAM metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochMaxRAM" title="avalanche.evaluation.metrics.EpochMaxRAM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochMaxRAM</span></code></a></p></td>
<td><p>The Epoch Max RAM metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceMaxRAM" title="avalanche.evaluation.metrics.ExperienceMaxRAM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceMaxRAM</span></code></a></p></td>
<td><p>The Experience Max RAM metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamMaxRAM" title="avalanche.evaluation.metrics.StreamMaxRAM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamMaxRAM</span></code></a></p></td>
<td><p>The Stream Max RAM metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ElapsedTime" title="avalanche.evaluation.metrics.ElapsedTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ElapsedTime</span></code></a></p></td>
<td><p>The standalone Elapsed Time metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MinibatchTime" title="avalanche.evaluation.metrics.MinibatchTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MinibatchTime</span></code></a></p></td>
<td><p>The minibatch time metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.EpochTime" title="avalanche.evaluation.metrics.EpochTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EpochTime</span></code></a></p></td>
<td><p>The epoch elapsed time metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.RunningEpochTime" title="avalanche.evaluation.metrics.RunningEpochTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RunningEpochTime</span></code></a></p></td>
<td><p>The running epoch time metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ExperienceTime" title="avalanche.evaluation.metrics.ExperienceTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExperienceTime</span></code></a></p></td>
<td><p>The experience time metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.StreamTime" title="avalanche.evaluation.metrics.StreamTime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">StreamTime</span></code></a></p></td>
<td><p>The stream time metric.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.accuracy_metrics" title="avalanche.evaluation.metrics.accuracy_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">accuracy_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.cpu_usage_metrics" title="avalanche.evaluation.metrics.cpu_usage_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu_usage_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.disk_usage_metrics" title="avalanche.evaluation.metrics.disk_usage_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">disk_usage_metrics</span></code></a>(*, paths_to_monitor=None, minibatch=False, epoch=False, experience=False, stream=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.forgetting_metrics" title="avalanche.evaluation.metrics.forgetting_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forgetting_metrics</span></code></a>(*, experience=False, stream=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.gpu_usage_metrics" title="avalanche.evaluation.metrics.gpu_usage_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gpu_usage_metrics</span></code></a>(gpu_id, every=0.5, minibatch=False, epoch=False, experience=False, stream=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.loss_metrics" title="avalanche.evaluation.metrics.loss_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loss_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.MAC_metrics" title="avalanche.evaluation.metrics.MAC_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MAC_metrics</span></code></a>(*, minibatch=False, epoch=False, experience=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.ram_usage_metrics" title="avalanche.evaluation.metrics.ram_usage_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ram_usage_metrics</span></code></a>(*, every=1, minibatch=False, epoch=False, experience=False, stream=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.evaluation.metrics.timing_metrics" title="avalanche.evaluation.metrics.timing_metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">timing_metrics</span></code></a>(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) → List[PluginMetric]</p></td>
<td><p>Helper method that can be used to obtain the desired set of</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt id="avalanche.evaluation.metrics.Mean">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">Mean</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The standalone mean metric.</p>
<p>This utility metric is a general purpose metric that can be used to keep
track of the mean of a sequence of values.</p>
<p>Creates an instance of the mean metric.</p>
<p>This metric in its initial state will return a mean value of 0.
The metric can be updated by using the <cite>update</cite> method while the mean
can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">SupportsFloat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">SupportsFloat</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running mean given the value.</p>
<p>The value can be weighted with a custom value, defined by the <cite>weight</cite>
parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> – The value to be used to update the mean.</p></li>
<li><p><strong>weight</strong> – The weight of the value. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the mean.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The mean, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Mean.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Mean.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Mean.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Sum">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">Sum</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Sum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The standalone sum metric.</p>
<p>This utility metric is a general purpose metric that can be used to keep
track of the sum of a sequence of values.</p>
<p>Beware that this metric only supports summing numbers and the result is
always a float value, even when <cite>update</cite> is called by passing <a href="#id1"><span class="problematic" id="id2">`</span></a>int`s only.</p>
<p>Creates an instance of the sum metric.</p>
<p>This metric in its initial state will return a sum value of 0.
The metric can be updated by using the <cite>update</cite> method while the sum
can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">SupportsFloat</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Sum.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running sum given the value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value</strong> – The value to be used to update the sum.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Sum.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the sum.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The sum, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Sum.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mean/#Sum.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Sum.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Accuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">Accuracy</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The Accuracy metric. This is a standalone metric
used to compute more specific ones.</p>
<p>Instances of this metric keeps the running average accuracy
over multiple &lt;prediction, target&gt; pairs of Tensors,
provided incrementally.
The “prediction” and “target” tensors may contain plain labels or
one-hot/logit vectors.</p>
<p>Each time <cite>result</cite> is called, this metric emits the average accuracy
across all predictions made since the last <cite>reset</cite>.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an accuracy value of 0.</p>
<p>Creates an instance of the standalone Accuracy metric.</p>
<p>By default this metric in its initial state will return an accuracy
value of 0. The metric can be updated by using the <cite>update</cite> method
while the running accuracy can be retrieved using the <cite>result</cite> method.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.Accuracy._mean_accuracy">
<code class="sig-name descname"><span class="pre">_mean_accuracy</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy._mean_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The mean utility that will be used to store the running accuracy.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicted_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">true_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running accuracy given the true and predicted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>predicted_y</strong> – The model prediction. Both labels and logit vectors
are supported.</p></li>
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the running accuracy.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running accuracy, as a float value between 0 and 1.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Accuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#Accuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Accuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MinibatchAccuracy</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch plugin accuracy metric.
This metric only works at training time.</p>
<p>This metric computes the average accuracy over patterns
from a single minibatch.
It reports the result after each iteration.</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochAccuracy" title="avalanche.evaluation.metrics.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochAccuracy</span></code></a> instead.</p>
<p>Creates an instance of the MinibatchAccuracy metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchAccuracy.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#MinibatchAccuracy.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchAccuracy.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">EpochAccuracy</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average accuracy over a single training epoch.
This plugin metric only works at training time.</p>
<p>The accuracy will be logged after each training epoch by computing
the number of correctly predicted patterns during the epoch divided by
the overall number of patterns encountered in that epoch.</p>
<p>Creates an instance of the EpochAccuracy metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochAccuracy.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#EpochAccuracy.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochAccuracy.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">RunningEpochAccuracy</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="accuracy/#avalanche.evaluation.metrics.accuracy.EpochAccuracy" title="avalanche.evaluation.metrics.accuracy.EpochAccuracy"><code class="xref py py-class docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.accuracy.EpochAccuracy</span></code></a></p>
<p>The average accuracy across all minibatches up to the current
epoch iteration.
This plugin metric only works at training time.</p>
<p>At each iteration, this metric logs the accuracy averaged over all patterns
seen so far in the current epoch.
The metric resets its state after each training epoch.</p>
<p>Creates an instance of the RunningEpochAccuracy metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochAccuracy.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#RunningEpochAccuracy.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochAccuracy.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceAccuracy</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#ExperienceAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>At the end of each experience, this plugin metric reports
the average accuracy over all patterns seen in that experience.
This metric only works at eval time.</p>
<p>Creates an instance of ExperienceAccuracy metric</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceAccuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#ExperienceAccuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceAccuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#ExperienceAccuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceAccuracy.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#ExperienceAccuracy.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceAccuracy.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceAccuracy.after_eval_iteration">
<code class="sig-name descname"><span class="pre">after_eval_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#ExperienceAccuracy.after_eval_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceAccuracy.after_eval_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of an iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceAccuracy.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#ExperienceAccuracy.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceAccuracy.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#ExperienceAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceAccuracy.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#ExperienceAccuracy.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceAccuracy.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamAccuracy">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamAccuracy</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#StreamAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamAccuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>At the end of the entire stream of experiences, this plugin metric
reports the average accuracy over all patterns seen in all experiences.
This metric only works at eval time.</p>
<p>Creates an instance of StreamAccuracy metric</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamAccuracy.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#StreamAccuracy.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamAccuracy.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamAccuracy.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#StreamAccuracy.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamAccuracy.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamAccuracy.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#StreamAccuracy.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamAccuracy.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamAccuracy.after_eval_iteration">
<code class="sig-name descname"><span class="pre">after_eval_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#StreamAccuracy.after_eval_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamAccuracy.after_eval_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of an iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamAccuracy.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#StreamAccuracy.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamAccuracy.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamAccuracy._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#StreamAccuracy._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamAccuracy._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamAccuracy.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#StreamAccuracy.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamAccuracy.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.accuracy_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">accuracy_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_running</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/accuracy/#accuracy_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.accuracy_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
plugin metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log
the minibatch accuracy at training time.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log
the epoch accuracy at training time.</p></li>
<li><p><strong>epoch_running</strong> – If True, will return a metric able to log
the running epoch accuracy at training time.</p></li>
<li><p><strong>experience</strong> – If True, will return a metric able to log
the accuracy on each evaluation experience.</p></li>
<li><p><strong>stream</strong> – If True, will return a metric able to log
the accuracy averaged over the entire evaluation stream of experiences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ConfusionMatrix</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="pre">true</span><span class="p"><span class="pre">,</span> </span><span class="pre">pred</span><span class="p"><span class="pre">,</span> </span><span class="pre">all</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[Tensor]</span></code></p>
<p>The standalone confusion matrix metric.</p>
<p>Instances of this metric keep track of the confusion matrix by receiving a
pair of “ground truth” and “prediction” Tensors describing the labels of a
minibatch. Those two tensors can both contain plain labels or
one-hot/logit vectors.</p>
<p>The result is the unnormalized running confusion matrix.</p>
<p>Beware that by default the confusion matrix size will depend on the value of
the maximum label as detected by looking at both the ground truth and
predictions Tensors. When passing one-hot/logit vectors, this
metric will try to infer the number of classes from the vector sizes.
Otherwise, the maximum label value encountered in the truth/prediction
Tensors will be used. It is recommended to set the (initial) number of
classes in the constructor.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an empty Tensor.</p>
<p>Creates an instance of the standalone confusion matrix metric.</p>
<p>By default this metric in its initial state will return an empty Tensor.
The metric can be updated by using the <cite>update</cite> method while the running
confusion matrix can be retrieved using the <cite>result</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> – The initial number of classes. Defaults to None,
which means that the number of classes will be inferred from
ground truth and prediction Tensors (see class description for more
details).</p></li>
<li><p><strong>normalize</strong> – how to normalize confusion matrix.
None to not normalize</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix._cm_tensor">
<code class="sig-name descname"><span class="pre">_cm_tensor</span></code><em class="property"> <span class="pre">:Optional[Tensor]</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix._cm_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The Tensor where the running confusion matrix is stored.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">true_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicted_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running confusion matrix given the true and predicted labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>true_y</strong> – The ground truth. Both labels and one-hot vectors
are supported.</p></li>
<li><p><strong>predicted_y</strong> – The ground truth. Both labels and logit vectors
are supported.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tensor</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the unnormalized confusion matrix.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running confusion matrix, as a Tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<p>Calling this method will <em>not</em> reset the default number of classes
optionally defined in the constructor optional parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix._normalize_cm">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">_normalize_cm</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cm</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalization</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="pre">true</span><span class="p"><span class="pre">,</span> </span><span class="pre">pred</span><span class="p"><span class="pre">,</span> </span><span class="pre">all</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix._normalize_cm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix._normalize_cm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ConfusionMatrix.nan_to_num">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">nan_to_num</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">matrix</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tensor</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#ConfusionMatrix.nan_to_num"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ConfusionMatrix.nan_to_num" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamConfusionMatrix</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="pre">true</span><span class="p"><span class="pre">,</span> </span><span class="pre">pred</span><span class="p"><span class="pre">,</span> </span><span class="pre">all</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_image</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_creator</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Image</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">default_cm_image_creator</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Tensor]</span></code></p>
<p>The Stream Confusion Matrix metric.
This plugin metric only works on the eval phase.</p>
<p>At the end of the eval phase, this metric logs the confusion matrix
relative to all the patterns seen during eval.</p>
<p>The metric can log either a Tensor or a PIL Image representing the
confusion matrix.</p>
<p>Creates an instance of the Stream Confusion Matrix metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> – <p>When not None, is used to properly define the
amount of rows/columns in the confusion matrix. When None, the
matrix will have many rows/columns as the maximum value of the
predicted and true pattern labels. Can be either an int, in which
case the same value will be used across all experiences, or a
dictionary defining the amount of classes for each experience (key =</p>
<blockquote>
<div><p>experience label, value = amount of classes). Defaults to None.</p>
</div></blockquote>
</p></li>
<li><p><strong>normalize</strong> – Normalizes confusion matrix over the true (rows),
predicted (columns) conditions or all the population. If None,
confusion matrix will not be normalized. Valid values are: ‘true’,
‘pred’ and ‘all’ or None.</p></li>
<li><p><strong>save_image</strong> – If True, a graphical representation of the confusion
matrix will be logged, too. If False, only the Tensor representation
will be logged. Defaults to True.</p></li>
<li><p><strong>image_creator</strong> – A callable that, given the tensor representation
of the confusion matrix, returns a graphical representation of the
matrix as a PIL Image. Defaults to <cite>default_cm_image_creator</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tensor</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">true_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicted_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix.after_eval_iteration">
<code class="sig-name descname"><span class="pre">after_eval_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix.after_eval_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix.after_eval_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of an iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamConfusionMatrix.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/confusion_matrix/#StreamConfusionMatrix.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamConfusionMatrix.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.CPUUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">CPUUsage</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#CPUUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The standalone CPU usage metric.</p>
<p>Instances of this metric compute the average CPU usage as a float value.
The metric starts tracking the CPU usage when the <cite>update</cite> method is called
for the first time. That is, the tracking does not start at the time the
constructor is invoked.</p>
<p>Calling the <cite>update</cite> method more than twice will update the metric to the
average usage between the first and the last call to <cite>update</cite>.</p>
<p>The result, obtained using the <cite>result</cite> method, is the usage computed
as stated above.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an usage value of 0.</p>
<p>Creates an instance of the standalone CPU usage metric.</p>
<p>By default this metric in its initial state will return a CPU usage
value of 0. The metric can be updated by using the <cite>update</cite> method
while the average CPU usage can be retrieved using the <cite>result</cite> method.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.CPUUsage._mean_usage">
<code class="sig-name descname"><span class="pre">_mean_usage</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage._mean_usage" title="Permalink to this definition">¶</a></dt>
<dd><p>The mean utility that will be used to store the average usage.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.CPUUsage._process_handle">
<code class="sig-name descname"><span class="pre">_process_handle</span></code><em class="property"> <span class="pre">:Optional[Process]</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage._process_handle" title="Permalink to this definition">¶</a></dt>
<dd><p>The process handle, lazily initialized.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.CPUUsage._first_update">
<code class="sig-name descname"><span class="pre">_first_update</span></code><em class="property"> <span class="pre">=</span> <span class="pre">True</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage._first_update" title="Permalink to this definition">¶</a></dt>
<dd><p>An internal flag to keep track of the first call to the <cite>update</cite> method.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.CPUUsage.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#CPUUsage.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running CPU usage.</p>
<p>For more info on how to set the starting moment see the class
description.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.CPUUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#CPUUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the average CPU usage.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The average CPU usage, as a float value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.CPUUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#CPUUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.CPUUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchCPUUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MinibatchCPUUsage</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCPUUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCPUUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch CPU usage metric.
This plugin metric only works at training time.</p>
<p>This metric “logs” the CPU usage for each iteration.</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochCPUUsage" title="avalanche.evaluation.metrics.EpochCPUUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochCPUUsage</span></code></a>.</p>
<p>Creates an instance of the minibatch CPU usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCPUUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCPUUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCPUUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCPUUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCPUUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCPUUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCPUUsage.before_training_iteration">
<code class="sig-name descname"><span class="pre">before_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCPUUsage.before_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCPUUsage.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before the start of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCPUUsage.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCPUUsage.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCPUUsage.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCPUUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCPUUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCPUUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchCPUUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#MinibatchCPUUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchCPUUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochCPUUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">EpochCPUUsage</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCPUUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCPUUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Epoch CPU usage metric.
This plugin metric only works at training time.</p>
<p>The average usage will be logged after each epoch.</p>
<p>Creates an instance of the epoch CPU usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCPUUsage.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCPUUsage.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCPUUsage.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCPUUsage.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCPUUsage.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCPUUsage.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCPUUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCPUUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCPUUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCPUUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCPUUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCPUUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCPUUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCPUUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCPUUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochCPUUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#EpochCPUUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochCPUUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RunningEpochCPUUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">RunningEpochCPUUsage</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#RunningEpochCPUUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The running epoch CPU usage metric.
This plugin metric only works at training time</p>
<p>After each iteration, the metric logs the average CPU usage up
to the current epoch iteration.</p>
<p>Creates an instance of the average epoch cpu usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochCPUUsage.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#RunningEpochCPUUsage.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochCPUUsage.before_training_iteration">
<code class="sig-name descname"><span class="pre">before_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#RunningEpochCPUUsage.before_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before the start of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochCPUUsage.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#RunningEpochCPUUsage.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochCPUUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#RunningEpochCPUUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochCPUUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#RunningEpochCPUUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochCPUUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#RunningEpochCPUUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochCPUUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#RunningEpochCPUUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochCPUUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceCPUUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceCPUUsage</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#ExperienceCPUUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceCPUUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average experience CPU usage metric.
This plugin metric works only at eval time.</p>
<p>After each experience, this metric emits the average CPU usage on that
experienc.</p>
<p>Creates an instance of the experience CPU usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceCPUUsage.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#ExperienceCPUUsage.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceCPUUsage.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceCPUUsage.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#ExperienceCPUUsage.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceCPUUsage.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceCPUUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#ExperienceCPUUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceCPUUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceCPUUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#ExperienceCPUUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceCPUUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceCPUUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#ExperienceCPUUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceCPUUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceCPUUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#ExperienceCPUUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceCPUUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamCPUUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamCPUUsage</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StreamCPUUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamCPUUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average stream CPU usage metric.
This plugin metric works only at eval time.</p>
<p>After the entire evaluation stream, this metric emits
the average CPU usage on all experiences.</p>
<p>Creates an instance of the stream CPU usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamCPUUsage.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StreamCPUUsage.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamCPUUsage.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamCPUUsage.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StreamCPUUsage.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamCPUUsage.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamCPUUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StreamCPUUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamCPUUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamCPUUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StreamCPUUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamCPUUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamCPUUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StreamCPUUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamCPUUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamCPUUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#StreamCPUUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamCPUUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.cpu_usage_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">cpu_usage_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_running</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/cpu_usage/#cpu_usage_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.cpu_usage_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
plugin metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
CPU usage</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch
CPU usage</p></li>
<li><p><strong>epoch_running</strong> – If True, will return a metric able to log the running
epoch CPU usage.</p></li>
<li><p><strong>experience</strong> – If True, will return a metric able to log the experience
CPU usage.</p></li>
<li><p><strong>stream</strong> – If True, will return a metric able to log the evaluation
stream CPU usage.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.DiskUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">DiskUsage</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths_to_monitor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">PathAlike</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">PathAlike</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The standalone disk usage metric.</p>
<p>This metric can be used to monitor the size of a set of directories.
e.g. This can be useful to monitor the size of a replay buffer,</p>
<p>Creates an instance of the standalone disk usage metric.</p>
<p>The <cite>result</cite> method will return the sum of the size
of the directories specified as the first parameter in KiloBytes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>paths_to_monitor</strong> – a path or a list of paths to monitor. If None,
the current working directory is used. Defaults to None.</p>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the disk usage statistics.</p>
<p>:return None.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the disk usage as computed during the last call to the
<cite>update</cite> method.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The disk usage or None if <cite>update</cite> was not invoked yet.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.DiskUsage.get_dir_size">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">get_dir_size</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#DiskUsage.get_dir_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.DiskUsage.get_dir_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchDiskUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MinibatchDiskUsage</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths_to_monitor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#MinibatchDiskUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchDiskUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch Disk usage metric.
This plugin metric only works at training time.</p>
<p>At the end of each iteration, this metric logs the total
size (in KB) of all the monitored paths.</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochDiskUsage" title="avalanche.evaluation.metrics.EpochDiskUsage"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochDiskUsage</span></code></a>.</p>
<p>Creates an instance of the minibatch Disk usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchDiskUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#MinibatchDiskUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchDiskUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchDiskUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#MinibatchDiskUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchDiskUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchDiskUsage.before_training_iteration">
<code class="sig-name descname"><span class="pre">before_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#MinibatchDiskUsage.before_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchDiskUsage.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before the start of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchDiskUsage.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#MinibatchDiskUsage.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchDiskUsage.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchDiskUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#MinibatchDiskUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchDiskUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchDiskUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#MinibatchDiskUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchDiskUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochDiskUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">EpochDiskUsage</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths_to_monitor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#EpochDiskUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochDiskUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Epoch Disk usage metric.
This plugin metric only works at training time.</p>
<p>At the end of each epoch, this metric logs the total
size (in KB) of all the monitored paths.</p>
<p>Creates an instance of the epoch Disk usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochDiskUsage.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#EpochDiskUsage.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochDiskUsage.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochDiskUsage.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#EpochDiskUsage.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochDiskUsage.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochDiskUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#EpochDiskUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochDiskUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochDiskUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#EpochDiskUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochDiskUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochDiskUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#EpochDiskUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochDiskUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochDiskUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#EpochDiskUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochDiskUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceDiskUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceDiskUsage</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths_to_monitor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#ExperienceDiskUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceDiskUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average experience Disk usage metric.
This plugin metric works only at eval time.</p>
<p>At the end of each experience, this metric logs the total
size (in KB) of all the monitored paths.</p>
<p>Creates an instance of the experience Disk usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceDiskUsage.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#ExperienceDiskUsage.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceDiskUsage.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceDiskUsage.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#ExperienceDiskUsage.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceDiskUsage.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceDiskUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#ExperienceDiskUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceDiskUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceDiskUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#ExperienceDiskUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceDiskUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceDiskUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#ExperienceDiskUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceDiskUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceDiskUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#ExperienceDiskUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceDiskUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamDiskUsage">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamDiskUsage</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">paths_to_monitor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#StreamDiskUsage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamDiskUsage" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average stream Disk usage metric.
This plugin metric works only at eval time.</p>
<p>At the end of the eval stream, this metric logs the total
size (in KB) of all the monitored paths.</p>
<p>Creates an instance of the stream Disk usage metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamDiskUsage.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#StreamDiskUsage.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamDiskUsage.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamDiskUsage.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#StreamDiskUsage.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamDiskUsage.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamDiskUsage.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#StreamDiskUsage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamDiskUsage.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamDiskUsage.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#StreamDiskUsage.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamDiskUsage.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamDiskUsage._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#StreamDiskUsage._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamDiskUsage._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamDiskUsage.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#StreamDiskUsage.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamDiskUsage.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.disk_usage_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">disk_usage_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paths_to_monitor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/disk_usage/#disk_usage_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.disk_usage_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
standalone metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
Disk usage</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch
Disk usage</p></li>
<li><p><strong>experience</strong> – If True, will return a metric able to log the experience
Disk usage.</p></li>
<li><p><strong>stream</strong> – If True, will return a metric able to log the evaluation
stream Disk usage.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Forgetting">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">Forgetting</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#Forgetting"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[Union[float,</span> <span class="pre">None,</span> <span class="pre">Dict[int,</span> <span class="pre">float]]]</span></code></p>
<p>The standalone Forgetting metric.
This metric returns the forgetting relative to a specific key.
Alternatively, this metric returns a dict in which each key is associated
to the forgetting.
Forgetting is computed as the difference between the first value recorded
for a specific key and the last value recorded for that key.
The value associated to a key can be update with the <cite>update</cite> method.</p>
<p>At initialization, this metric returns an empty dictionary.</p>
<p>Creates an instance of the standalone Forgetting metric</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.Forgetting.initial">
<code class="sig-name descname"><span class="pre">initial</span></code><em class="property"> <span class="pre">:Dict[int,</span> <span class="pre">float]</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting.initial" title="Permalink to this definition">¶</a></dt>
<dd><p>The initial value for each key.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.Forgetting.last">
<code class="sig-name descname"><span class="pre">last</span></code><em class="property"> <span class="pre">:Dict[int,</span> <span class="pre">float]</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting.last" title="Permalink to this definition">¶</a></dt>
<dd><p>The last value detected for each key</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Forgetting.update_initial">
<code class="sig-name descname"><span class="pre">update_initial</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#Forgetting.update_initial"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting.update_initial" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Forgetting.update_last">
<code class="sig-name descname"><span class="pre">update_last</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#Forgetting.update_last"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting.update_last" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Forgetting.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#Forgetting.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Forgetting.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span> </span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#Forgetting.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Forgetting is returned only for keys encountered twice.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>k</strong> – the key for which returning forgetting. If k has not
updated at least twice it returns None. If k is None,
forgetting will be returned for all keys encountered at least
twice.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the difference between the first and last value encountered
for k, if k is not None. It returns None if k has not been updated
at least twice. If k is None, returns a dictionary
containing keys whose value has been updated at least twice. The
associated value is the difference between the first and last
value recorded for that key.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Forgetting.reset_last">
<code class="sig-name descname"><span class="pre">reset_last</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#Forgetting.reset_last"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting.reset_last" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Forgetting.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#Forgetting.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Forgetting.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric internal state.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceForgetting</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The ExperienceForgetting metric, describing the accuracy loss
detected for a certain experience.</p>
<p>This plugin metric, computed separately for each experience,
is the difference between the accuracy result obtained after
first training on a experience and the accuracy result obtained
on the same experience at the end of successive experiences.</p>
<p>This metric is computed during the eval phase only.</p>
<p>Creates an instance of the ExperienceForgetting metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.forgetting">
<code class="sig-name descname"><span class="pre">forgetting</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.forgetting" title="Permalink to this definition">¶</a></dt>
<dd><p>The general metric to compute forgetting</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting._current_accuracy">
<code class="sig-name descname"><span class="pre">_current_accuracy</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting._current_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The average accuracy over the current evaluation experience</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.eval_exp_id">
<code class="sig-name descname"><span class="pre">eval_exp_id</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.eval_exp_id" title="Permalink to this definition">¶</a></dt>
<dd><p>The current evaluation experience id</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.train_exp_id">
<code class="sig-name descname"><span class="pre">train_exp_id</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.train_exp_id" title="Permalink to this definition">¶</a></dt>
<dd><p>The last encountered training experience id</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<p>Beware that this will also reset the initial accuracy of each
experience!</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.reset_last_accuracy">
<code class="sig-name descname"><span class="pre">reset_last_accuracy</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.reset_last_accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.reset_last_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the last accuracy.</p>
<p>This will preserve the initial accuracy value of each experience.
To be used at the beginning of each eval experience.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update forgetting metric.
See <cite>Forgetting</cite> for more detailed information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> – key to update</p></li>
<li><p><strong>v</strong> – value associated to k</p></li>
<li><p><strong>initial</strong> – update initial value. If False, update
last value.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span> </span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.result" title="Permalink to this definition">¶</a></dt>
<dd><p>See <cite>Forgetting</cite> documentation for more detailed information.</p>
<p>k: optional key from which compute forgetting.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.before_training_exp">
<code class="sig-name descname"><span class="pre">before_training_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.before_training_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.before_training_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.after_eval_iteration">
<code class="sig-name descname"><span class="pre">after_eval_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.after_eval_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.after_eval_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of an iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceForgetting.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#ExperienceForgetting.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceForgetting.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamForgetting">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamForgetting</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[Dict[int,</span> <span class="pre">float]]</span></code></p>
<p>The StreamForgetting metric, describing the average evaluation accuracy loss
detected over all experiences observed during training.</p>
<p>This plugin metric, computed over all observed experiences during training,
is the average over the difference between the accuracy result obtained
after first training on a experience and the accuracy result obtained
on the same experience at the end of successive experiences.</p>
<p>This metric is computed during the eval phase only.</p>
<p>Creates an instance of the StreamForgetting metric.</p>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.StreamForgetting.stream_forgetting">
<code class="sig-name descname"><span class="pre">stream_forgetting</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.stream_forgetting" title="Permalink to this definition">¶</a></dt>
<dd><p>The average forgetting over all experiences</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.StreamForgetting.forgetting">
<code class="sig-name descname"><span class="pre">forgetting</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.forgetting" title="Permalink to this definition">¶</a></dt>
<dd><p>The general metric to compute forgetting</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.StreamForgetting._current_accuracy">
<code class="sig-name descname"><span class="pre">_current_accuracy</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting._current_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>The average accuracy over the current evaluation experience</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.StreamForgetting.eval_exp_id">
<code class="sig-name descname"><span class="pre">eval_exp_id</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.eval_exp_id" title="Permalink to this definition">¶</a></dt>
<dd><p>The current evaluation experience id</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.StreamForgetting.train_exp_id">
<code class="sig-name descname"><span class="pre">train_exp_id</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.train_exp_id" title="Permalink to this definition">¶</a></dt>
<dd><p>The last encountered training experience id</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the forgetting metrics.</p>
<p>Beware that this will also reset the initial accuracy of each
experience!</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.reset_last_accuracy">
<code class="sig-name descname"><span class="pre">reset_last_accuracy</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.reset_last_accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.reset_last_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the last accuracy.</p>
<p>This will preserve the initial accuracy value of each experience.
To be used at the beginning of each eval experience.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.exp_update">
<code class="sig-name descname"><span class="pre">exp_update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.exp_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.exp_update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update forgetting metric.
See <cite>Forgetting</cite> for more detailed information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k</strong> – key to update</p></li>
<li><p><strong>v</strong> – value associated to k</p></li>
<li><p><strong>initial</strong> – update initial value. If False, update
last value.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.exp_result">
<code class="sig-name descname"><span class="pre">exp_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span> </span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.exp_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.exp_result" title="Permalink to this definition">¶</a></dt>
<dd><p>Result for experience defined by a key.
See <cite>Forgetting</cite> documentation for more detailed information.</p>
<p>k: optional key from which compute forgetting.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span> </span><span class="pre">None</span><span class="p"><span class="pre">,</span> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.result" title="Permalink to this definition">¶</a></dt>
<dd><p>The average forgetting over all experience.</p>
<p>k: optional key from which compute forgetting.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.before_training_exp">
<code class="sig-name descname"><span class="pre">before_training_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.before_training_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.before_training_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.after_eval_iteration">
<code class="sig-name descname"><span class="pre">after_eval_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.after_eval_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.after_eval_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of an iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamForgetting.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#StreamForgetting.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamForgetting.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.forgetting_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">forgetting_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/forgetting/#forgetting_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.forgetting_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
plugin metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experience</strong> – If True, will return a metric able to log
the forgetting on each evaluation experience.</p></li>
<li><p><strong>stream</strong> – If True, will return a metric able to log
the forgetting averaged over the evaluation stream experiences,
which have been observed during training.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MaxGPU">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MaxGPU</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MaxGPU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The standalone GPU usage metric.
Important: this metric approximates the real maximum GPU percentage</p>
<blockquote>
<div><p>usage since it sample at discrete amount of time the GPU values.</p>
</div></blockquote>
<p>Instances of this metric keeps the maximum GPU usage percentage detected.
The <cite>start_thread</cite> method starts the usage tracking.
The <cite>stop_thread</cite> method stops the tracking.</p>
<p>The result, obtained using the <cite>result</cite> method, is the usage in mega-bytes.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an usage value of 0.</p>
<p>Creates an instance of the GPU usage metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – GPU device ID.</p></li>
<li><p><strong>every</strong> – seconds after which update the maximum GPU
usage</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.MaxGPU.thread">
<code class="sig-name descname"><span class="pre">thread</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU.thread" title="Permalink to this definition">¶</a></dt>
<dd><p>Thread executing GPU monitoring code</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.MaxGPU.stop_f">
<code class="sig-name descname"><span class="pre">stop_f</span></code><em class="property"> <span class="pre">=</span> <span class="pre">False</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU.stop_f" title="Permalink to this definition">¶</a></dt>
<dd><p>Flag to stop the thread</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.MaxGPU.max_usage">
<code class="sig-name descname"><span class="pre">max_usage</span></code><em class="property"> <span class="pre">=</span> <span class="pre">0</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU.max_usage" title="Permalink to this definition">¶</a></dt>
<dd><p>Main metric result. Max GPU usage.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxGPU._f">
<code class="sig-name descname"><span class="pre">_f</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MaxGPU._f"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU._f" title="Permalink to this definition">¶</a></dt>
<dd><p>Until a stop signal is encountered,
this function monitors each <cite>every</cite> seconds
the maximum amount of GPU used by the process</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxGPU.start_thread">
<code class="sig-name descname"><span class="pre">start_thread</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MaxGPU.start_thread"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU.start_thread" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxGPU.stop_thread">
<code class="sig-name descname"><span class="pre">stop_thread</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MaxGPU.stop_thread"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU.stop_thread" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxGPU.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MaxGPU.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxGPU.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MaxGPU.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxGPU.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the max GPU percentage value.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The percentage GPU usage as a float value in range [0, 1].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MinibatchMaxGPU</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Minibatch Max GPU metric.
This plugin metric only works at training time.</p>
<p>Creates an instance of the Minibatch Max GPU metric</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – GPU device ID.</p></li>
<li><p><strong>every</strong> – seconds after which update the maximum GPU
usage</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU.before_training">
<code class="sig-name descname"><span class="pre">before_training</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU.before_training"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU.before_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU.before_training_iteration">
<code class="sig-name descname"><span class="pre">before_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU.before_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before the start of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU.after_training">
<code class="sig-name descname"><span class="pre">after_training</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU.after_training"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU.after_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxGPU.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#MinibatchMaxGPU.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxGPU.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">EpochMaxGPU</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Epoch Max GPU metric.
This plugin metric only works at training time.</p>
<p>Creates an instance of the epoch Max GPU metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – GPU device ID.</p></li>
<li><p><strong>every</strong> – seconds after which update the maximum GPU
usage</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU.before_training">
<code class="sig-name descname"><span class="pre">before_training</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU.before_training"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU.before_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU.after_training">
<code class="sig-name descname"><span class="pre">after_training</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU.after_training"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU.after_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxGPU.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#EpochMaxGPU.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxGPU.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceMaxGPU</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Experience Max GPU metric.
This plugin metric only works at eval time.</p>
<p>Creates an instance of the Experience CPU usage metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – GPU device ID.</p></li>
<li><p><strong>every</strong> – seconds after which update the maximum GPU
usage</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxGPU.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#ExperienceMaxGPU.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxGPU.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamMaxGPU">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamMaxGPU</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#StreamMaxGPU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxGPU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Stream Max GPU metric.
This plugin metric only works at eval time.</p>
<p>Creates an instance of the Experience CPU usage metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – GPU device ID.</p></li>
<li><p><strong>every</strong> – seconds after which update the maximum GPU
usage</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxGPU.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#StreamMaxGPU.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxGPU.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxGPU.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#StreamMaxGPU.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxGPU.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxGPU.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#StreamMaxGPU.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxGPU.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxGPU.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#StreamMaxGPU.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxGPU.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxGPU._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#StreamMaxGPU._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxGPU._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxGPU.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#StreamMaxGPU.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxGPU.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.gpu_usage_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">gpu_usage_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gpu_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/gpu_usage/#gpu_usage_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.gpu_usage_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
plugin metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gpu_id</strong> – GPU device ID.</p></li>
<li><p><strong>every</strong> – seconds after which update the maximum GPU
usage</p></li>
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
max GPU usage.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch
max GPU usage.</p></li>
<li><p><strong>experience</strong> – If True, will return a metric able to log the experience
max GPU usage.</p></li>
<li><p><strong>stream</strong> – If True, will return a metric able to log the evaluation
max stream GPU usage.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.Loss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">Loss</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The standalone Loss metric. This is a general metric
used to compute more specific ones.</p>
<p>Instances of this metric keeps the running average loss
over multiple &lt;prediction, target&gt; pairs of Tensors,
provided incrementally.
The “prediction” and “target” tensors may contain plain labels or
one-hot/logit vectors.</p>
<p>Each time <cite>result</cite> is called, this metric emits the average loss
across all predictions made since the last <cite>reset</cite>.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return a loss value of 0.</p>
<p>Creates an instance of the loss metric.</p>
<p>By default this metric in its initial state will return a loss
value of 0. The metric can be updated by using the <cite>update</cite> method
while the running loss can be retrieved using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patterns</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the running loss given the loss Tensor and the minibatch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> – The loss Tensor. Different reduction types don’t affect
the result.</p></li>
<li><p><strong>patterns</strong> – The number of patterns in the minibatch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the running average loss per pattern.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The running loss, as a float.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.Loss.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#Loss.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.Loss.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchLoss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MinibatchLoss</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch loss metric.
This plugin metric only works at training time.</p>
<p>This metric computes the average loss over patterns
from a single minibatch.
It reports the result after each iteration.</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochLoss" title="avalanche.evaluation.metrics.EpochLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochLoss</span></code></a> instead.</p>
<p>Creates an instance of the MinibatchLoss metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchLoss.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#MinibatchLoss.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchLoss.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochLoss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">EpochLoss</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The average loss over a single training epoch.
This plugin metric only works at training time.</p>
<p>The loss will be logged after each training epoch by computing
the loss on the predicted patterns during the epoch divided by
the overall number of patterns encountered in that epoch.</p>
<p>Creates an instance of the EpochLoss metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochLoss.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#EpochLoss.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochLoss.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">RunningEpochLoss</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="loss/#avalanche.evaluation.metrics.loss.EpochLoss" title="avalanche.evaluation.metrics.loss.EpochLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">avalanche.evaluation.metrics.loss.EpochLoss</span></code></a></p>
<p>The average loss across all minibatches up to the current
epoch iteration.
This plugin metric only works at training time.</p>
<p>At each iteration, this metric logs the loss averaged over all patterns
seen so far in the current epoch.
The metric resets its state after each training epoch.</p>
<p>Creates an instance of the RunningEpochLoss metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochLoss.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#RunningEpochLoss.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochLoss.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceLoss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceLoss</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#ExperienceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>At the end of each experience, this metric reports
the average loss over all patterns seen in that experience.
This plugin metric only works at eval time.</p>
<p>Creates an instance of ExperienceLoss metric</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceLoss.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#ExperienceLoss.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceLoss.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#ExperienceLoss.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceLoss.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#ExperienceLoss.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceLoss.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceLoss.after_eval_iteration">
<code class="sig-name descname"><span class="pre">after_eval_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#ExperienceLoss.after_eval_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceLoss.after_eval_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of an iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceLoss.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#ExperienceLoss.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceLoss.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceLoss._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#ExperienceLoss._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceLoss.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#ExperienceLoss.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceLoss.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamLoss">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamLoss</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#StreamLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>At the end of the entire stream of experiences, this metric reports the
average loss over all patterns seen in all experiences.
This plugin metric only works at eval time.</p>
<p>Creates an instance of StreamLoss metric</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamLoss.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#StreamLoss.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamLoss.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamLoss.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#StreamLoss.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamLoss.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamLoss.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#StreamLoss.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamLoss.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamLoss.after_eval_iteration">
<code class="sig-name descname"><span class="pre">after_eval_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#StreamLoss.after_eval_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamLoss.after_eval_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of an iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamLoss.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#StreamLoss.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamLoss.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamLoss._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#StreamLoss._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamLoss._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamLoss.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#StreamLoss.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamLoss.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.loss_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">loss_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_running</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/loss/#loss_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.loss_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
plugin metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log
the minibatch loss at training time.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log
the epoch loss at training time.</p></li>
<li><p><strong>epoch_running</strong> – If True, will return a metric able to log
the running epoch loss at training time.</p></li>
<li><p><strong>experience</strong> – If True, will return a metric able to log
the loss on each evaluation experience.</p></li>
<li><p><strong>stream</strong> – If True, will return a metric able to log
the loss averaged over the entire evaluation stream of experiences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MAC">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MAC</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[int]</span></code></p>
<p>Standalone Multiply-and-accumulate metric. Provides a lower bound of the
computational cost of a model in a hardware-independent way by
computing the number of multiplications. Currently supports only
Linear or Conv2d modules. Other operations are ignored.</p>
<p>Creates an instance of the MAC metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the MAC metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – current model.</p></li>
<li><p><strong>dummy_input</strong> – A tensor of the correct size to feed as input
to model. It includes batch size</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MAC metric.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the number of MAC operations as computed in the previous call
to the <cite>update</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The number of MAC operations or None if <cite>update</cite> has not been
called yet.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.update_compute_cost">
<code class="sig-name descname"><span class="pre">update_compute_cost</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC.update_compute_cost"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.update_compute_cost" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MAC.is_recognized_module">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">is_recognized_module</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mod</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC.is_recognized_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC.is_recognized_module" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchMAC">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MinibatchMAC</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MinibatchMAC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMAC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch MAC metric.
This plugin metric only works at training time.</p>
<p>This metric computes the MAC over 1 pattern
from a single minibatch.
It reports the result after each iteration.</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochMAC" title="avalanche.evaluation.metrics.EpochMAC"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochMAC</span></code></a> instead.</p>
<p>Creates an instance of the MinibatchMAC metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMAC.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MinibatchMAC.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMAC.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMAC.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MinibatchMAC.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMAC.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMAC.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MinibatchMAC.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMAC.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMAC._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MinibatchMAC._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMAC._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMAC.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MinibatchMAC.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMAC.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochMAC">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">EpochMAC</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#EpochMAC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMAC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The MAC at the end of each epoch computed on a
single pattern.
This plugin metric only works at training time.</p>
<p>The MAC will be logged after each training epoch.</p>
<p>Creates an instance of the EpochMAC metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMAC.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#EpochMAC.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMAC.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMAC.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#EpochMAC.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMAC.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMAC.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#EpochMAC.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMAC.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMAC._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#EpochMAC._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMAC._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMAC.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#EpochMAC.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMAC.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceMAC">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceMAC</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#ExperienceMAC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMAC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>At the end of each experience, this metric reports the
MAC computed on a single pattern.
This plugin metric only works at eval time.</p>
<p>Creates an instance of ExperienceMAC metric</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMAC.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#ExperienceMAC.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMAC.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMAC.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#ExperienceMAC.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMAC.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMAC.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#ExperienceMAC.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMAC.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMAC._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#ExperienceMAC._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMAC._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMAC.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#ExperienceMAC.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMAC.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.MAC_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MAC_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/mac/#MAC_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MAC_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
plugin metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log
the MAC after each iteration at training time.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log
the MAC after each epoch at training time.</p></li>
<li><p><strong>experience</strong> – If True, will return a metric able to log
the MAC after each eval experience.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MaxRAM">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MaxRAM</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MaxRAM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The standalone RAM usage metric.
Important: this metric approximates the real maximum RAM usage since
it sample at discrete amount of time the RAM values.</p>
<p>Instances of this metric keeps the maximum RAM usage detected.
The <cite>start_thread</cite> method starts the usage tracking.
The <cite>stop_thread</cite> method stops the tracking.</p>
<p>The result, obtained using the <cite>result</cite> method, is the usage in mega-bytes.</p>
<p>The reset method will bring the metric to its initial state. By default
this metric in its initial state will return an usage value of 0.</p>
<p>Creates an instance of the RAM usage metric.
:param every: seconds after which update the maximum RAM</p>
<blockquote>
<div><p>usage</p>
</div></blockquote>
<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.MaxRAM._process_handle">
<code class="sig-name descname"><span class="pre">_process_handle</span></code><em class="property"> <span class="pre">:Optional[Process]</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM._process_handle" title="Permalink to this definition">¶</a></dt>
<dd><p>The process handle, lazily initialized.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.MaxRAM.stop_f">
<code class="sig-name descname"><span class="pre">stop_f</span></code><em class="property"> <span class="pre">=</span> <span class="pre">False</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM.stop_f" title="Permalink to this definition">¶</a></dt>
<dd><p>Flag to stop the thread</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.MaxRAM.max_usage">
<code class="sig-name descname"><span class="pre">max_usage</span></code><em class="property"> <span class="pre">=</span> <span class="pre">0</span></em><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM.max_usage" title="Permalink to this definition">¶</a></dt>
<dd><p>Main metric result. Max RAM usage.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.evaluation.metrics.MaxRAM.thread">
<code class="sig-name descname"><span class="pre">thread</span></code><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM.thread" title="Permalink to this definition">¶</a></dt>
<dd><p>Thread executing RAM monitoring code</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxRAM._f">
<code class="sig-name descname"><span class="pre">_f</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MaxRAM._f"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM._f" title="Permalink to this definition">¶</a></dt>
<dd><p>Until a stop signal is encountered,
this function monitors each <cite>every</cite> seconds
the maximum amount of RAM used by the process</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxRAM.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MaxRAM.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the RAM usage.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The average RAM usage in bytes, as a float value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxRAM.start_thread">
<code class="sig-name descname"><span class="pre">start_thread</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MaxRAM.start_thread"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM.start_thread" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxRAM.stop_thread">
<code class="sig-name descname"><span class="pre">stop_thread</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MaxRAM.stop_thread"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM.stop_thread" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MaxRAM.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MaxRAM.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MaxRAM.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MinibatchMaxRAM</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Minibatch Max RAM metric.
This plugin metric only works at training time.</p>
<p>Creates an instance of the Minibatch Max RAM metric
:param every: seconds after which update the maximum RAM</p>
<blockquote>
<div><p>usage</p>
</div></blockquote>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM.before_training">
<code class="sig-name descname"><span class="pre">before_training</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM.before_training"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM.before_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM.before_training_iteration">
<code class="sig-name descname"><span class="pre">before_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM.before_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before the start of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM.after_training">
<code class="sig-name descname"><span class="pre">after_training</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM.after_training"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM.after_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchMaxRAM.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#MinibatchMaxRAM.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchMaxRAM.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">EpochMaxRAM</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Epoch Max RAM metric.
This plugin metric only works at training time.</p>
<p>Creates an instance of the epoch Max RAM metric.
:param every: seconds after which update the maximum RAM</p>
<blockquote>
<div><p>usage</p>
</div></blockquote>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM.before_training">
<code class="sig-name descname"><span class="pre">before_training</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM.before_training"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM.before_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM.after_training">
<code class="sig-name descname"><span class="pre">after_training</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM.after_training"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM.after_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochMaxRAM.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#EpochMaxRAM.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochMaxRAM.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceMaxRAM</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Experience Max RAM metric.
This plugin metric only works at eval time.</p>
<p>Creates an instance of the Experience CPU usage metric.
:param every: seconds after which update the maximum RAM</p>
<blockquote>
<div><p>usage</p>
</div></blockquote>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceMaxRAM.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ExperienceMaxRAM.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceMaxRAM.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamMaxRAM">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamMaxRAM</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#StreamMaxRAM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxRAM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The Stream Max RAM metric.
This plugin metric only works at eval time.</p>
<p>Creates an instance of the Experience CPU usage metric.
:param every: seconds after which update the maximum RAM</p>
<blockquote>
<div><p>usage</p>
</div></blockquote>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxRAM.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#StreamMaxRAM.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxRAM.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxRAM.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#StreamMaxRAM.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxRAM.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxRAM.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#StreamMaxRAM.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxRAM.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxRAM.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#StreamMaxRAM.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxRAM.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxRAM._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#StreamMaxRAM._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxRAM._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamMaxRAM.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#StreamMaxRAM.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamMaxRAM.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.ram_usage_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ram_usage_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/ram_usage/#ram_usage_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ram_usage_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
plugin metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>every</strong> – seconds after which update the maximum RAM
usage</p></li>
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the minibatch
max RAM usage.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the epoch
max RAM usage.</p></li>
<li><p><strong>experience</strong> – If True, will return a metric able to log the experience
max RAM usage.</p></li>
<li><p><strong>stream</strong> – If True, will return a metric able to log the evaluation
max stream RAM usage.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ElapsedTime">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ElapsedTime</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric[float]</span></code></p>
<p>The standalone Elapsed Time metric.</p>
<p>Instances of this metric keep track of the time elapsed between calls to the
<cite>update</cite> method. The starting time is set when the <cite>update</cite> method is called
for the first time. That is, the starting time is <em>not</em> taken at the time
the constructor is invoked.</p>
<p>Calling the <cite>update</cite> method more than twice will update the metric to the
elapsed time between the first and the last call to <cite>update</cite>.</p>
<p>The result, obtained using the <cite>result</cite> method, is the time, in seconds,
computed as stated above.</p>
<p>The <cite>reset</cite> method will set the metric to its initial state, thus resetting
the initial time. This metric in its initial state (or if the <cite>update</cite>
method was invoked only once) will return an elapsed time of 0.</p>
<p>Creates an instance of the ElapsedTime metric.</p>
<p>This metric in its initial state (or if the <cite>update</cite> method was invoked
only once) will return an elapsed time of 0. The metric can be updated
by using the <cite>update</cite> method while the running accuracy can be retrieved
using the <cite>result</cite> method.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.update">
<code class="sig-name descname"><span class="pre">update</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the elapsed time.</p>
<p>For more info on how to set the initial time see the class description.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.result" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves the elapsed time.</p>
<p>Calling this method will not change the internal state of the metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The elapsed time, in seconds, as a float value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ElapsedTime.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ElapsedTime.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ElapsedTime.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric, including the initial time.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.MinibatchTime">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">MinibatchTime</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The minibatch time metric.
This plugin metric only works at training time.</p>
<p>This metric “logs” the elapsed time for each iteration.</p>
<p>If a more coarse-grained logging is needed, consider using
<a class="reference internal" href="#avalanche.evaluation.metrics.EpochTime" title="avalanche.evaluation.metrics.EpochTime"><code class="xref py py-class docutils literal notranslate"><span class="pre">EpochTime</span></code></a>.</p>
<p>Creates an instance of the minibatch time metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.before_training_iteration">
<code class="sig-name descname"><span class="pre">before_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.before_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before the start of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.MinibatchTime.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#MinibatchTime.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.MinibatchTime.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.EpochTime">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">EpochTime</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The epoch elapsed time metric.
This plugin metric only works at training time.</p>
<p>The elapsed time will be logged after each epoch.</p>
<p>Creates an instance of the epoch time metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.after_training_epoch">
<code class="sig-name descname"><span class="pre">after_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.after_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.after_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.EpochTime.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#EpochTime.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.EpochTime.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.RunningEpochTime">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">RunningEpochTime</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#RunningEpochTime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The running epoch time metric.
This plugin metric only works at training time.</p>
<p>For each iteration, this metric logs the average time
between the start of the
epoch and the current iteration.</p>
<p>Creates an instance of the running epoch time metric..</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochTime.before_training_epoch">
<code class="sig-name descname"><span class="pre">before_training_epoch</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#RunningEpochTime.before_training_epoch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochTime.before_training_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>train_epoch</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochTime.before_training_iteration">
<code class="sig-name descname"><span class="pre">before_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#RunningEpochTime.before_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochTime.before_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before the start of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochTime.after_training_iteration">
<code class="sig-name descname"><span class="pre">after_training_iteration</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#RunningEpochTime.after_training_iteration"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochTime.after_training_iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after the end of a training iteration by the
<cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochTime.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#RunningEpochTime.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochTime.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#RunningEpochTime.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochTime._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#RunningEpochTime._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.RunningEpochTime.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#RunningEpochTime.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.RunningEpochTime.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.ExperienceTime">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">ExperienceTime</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ExperienceTime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The experience time metric.
This plugin metric only works at eval time.</p>
<p>After each experience, this metric emits the average time of that
experience.</p>
<p>Creates an instance of the experience time metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceTime.before_eval_exp">
<code class="sig-name descname"><span class="pre">before_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ExperienceTime.before_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceTime.before_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceTime.after_eval_exp">
<code class="sig-name descname"><span class="pre">after_eval_exp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ExperienceTime.after_eval_exp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceTime.after_eval_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval_exp</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceTime.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ExperienceTime.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceTime.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ExperienceTime.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceTime._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ExperienceTime._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.ExperienceTime.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#ExperienceTime.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.ExperienceTime.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.evaluation.metrics.StreamTime">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">StreamTime</span></code><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StreamTime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">PluginMetric[float]</span></code></p>
<p>The stream time metric.
This metric only works at eval time.</p>
<p>After the entire evaluation stream,
this plugin metric emits the average time of that stream.</p>
<p>Creates an instance of the stream time metric.</p>
<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamTime.before_eval">
<code class="sig-name descname"><span class="pre">before_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StreamTime.before_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamTime.before_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called before <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamTime.after_eval">
<code class="sig-name descname"><span class="pre">after_eval</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StreamTime.after_eval"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamTime.after_eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Called after <cite>eval</cite> by the <cite>BaseStrategy</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamTime.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StreamTime.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamTime.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamTime.result">
<code class="sig-name descname"><span class="pre">result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">float</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StreamTime.result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamTime.result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamTime._package_result">
<code class="sig-name descname"><span class="pre">_package_result</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">BaseStrategy</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">MetricResult</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StreamTime._package_result"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamTime._package_result" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.evaluation.metrics.StreamTime.__str__">
<code class="sig-name descname"><span class="pre">__str__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#StreamTime.__str__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.StreamTime.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return str(self).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.evaluation.metrics.timing_metrics">
<code class="sig-prename descclassname"><span class="pre">avalanche.evaluation.metrics.</span></code><code class="sig-name descname"><span class="pre">timing_metrics</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minibatch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_running</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">PluginMetric</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../../_modules/avalanche/evaluation/metrics/timing/#timing_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.evaluation.metrics.timing_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method that can be used to obtain the desired set of
plugin metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – If True, will return a metric able to log the train
minibatch elapsed time.</p></li>
<li><p><strong>epoch</strong> – If True, will return a metric able to log the train epoch
elapsed time.</p></li>
<li><p><strong>epoch_running</strong> – If True, will return a metric able to log the running
train epoch elapsed time.</p></li>
<li><p><strong>experience</strong> – If True, will return a metric able to log the eval
experience elapsed time.</p></li>
<li><p><strong>stream</strong> – If True, will return a metric able to log the eval stream
elapsed time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of plugin metrics.</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, ContinualAI.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>